{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import warnings\n",
    "#warnings.simplefilter(\"ignore\", FutureWarning)  # openml deprecation of array return type\n",
    "warnings.simplefilter(\"ignore\", UserWarning)  # scikit-learn select k best\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)  # scikit-learn select k best\n",
    "\n",
    "from ticl.datasets import load_openml_list, open_cc_valid_dids, open_cc_dids\n",
    "from ticl.evaluation.baselines.tabular_baselines import knn_metric, catboost_metric, logistic_metric, xgb_metric, random_forest_metric, mlp_metric, hyperfast_metric, resnet_metric, mothernet_init_metric\n",
    "from ticl.evaluation.tabular_evaluation import evaluate, eval_on_datasets, transformer_metric\n",
    "from ticl.evaluation import tabular_metrics\n",
    "from ticl.prediction.tabpfn import TabPFNClassifier\n",
    "from ticl.evaluation.baselines import tabular_baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/TabPFN/mothernet/datasets/__init__.py:153: FutureWarning: Support for `output_format` of 'dict' will be removed in 0.15 and pandas dataframes will be returned instead. To ensure your code will continue to work, use `output_format`='dataframe'.\n",
      "  openml_list = openml.datasets.list_datasets(dids)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 149\n"
     ]
    }
   ],
   "source": [
    "from ticl.datasets import load_openml_list, open_cc_dids, open_cc_valid_dids, test_dids_classification\n",
    "\n",
    "cc_valid_datasets_multiclass, cc_valid_datasets_multiclass_df = load_openml_list(open_cc_valid_dids, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = 10000, num_feats=100, return_capped=True, classification=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc_valid_datasets_multiclass_df['NumberOfInstances'] =  cc_valid_datasets_multiclass_df['NumberOfInstances'].astype(int)\n",
    "cc_valid_datasets_multiclass_df['NumberOfFeatures'] =  cc_valid_datasets_multiclass_df['NumberOfFeatures'].astype(int)\n",
    "cc_valid_datasets_multiclass_df['NumberOfClasses'] =  cc_valid_datasets_multiclass_df['NumberOfClasses'].astype(int)\n",
    "\n",
    "# uncomment for latex table of datasets\n",
    "# print(cc_valid_datasets_multiclass_df[['did', 'name', 'NumberOfFeatures', 'NumberOfInstances', 'NumberOfClasses']].rename(columns={'NumberOfFeatures': \"d\", \"NumberOfInstances\":\"n\", \"NumberOfClasses\": \"k\"}).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "eval_positions = [1000]\n",
    "max_features = 100\n",
    "n_samples = 2000\n",
    "base_path = os.path.join('..')\n",
    "overwrite = False\n",
    "metric_used = tabular_metrics.auc_metric\n",
    "task_type = 'multiclass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline Evaluation\n",
    "This section runs baselines and saves results locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {base_path}/results\n",
    "!mkdir -p {base_path}/results/tabular/\n",
    "!mkdir -p {base_path}/results/tabular/multiclass/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_valid_datasets_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(skip_parameter_validation=True, assume_finite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ticl.evaluation.tabular_evaluation import eval_on_datasets\n",
    "from ticl.prediction.mothernet import ShiftClassifier, EnsembleMeta, MotherNetClassifier, MotherNetInitMLPClassifier\n",
    "from ticl.prediction.mothernet_additive import MotherNetAdditiveClassifier\n",
    "from ticl.evaluation.baselines.distill_mlp import DistilledTabPFNMLP\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from functools import partial\n",
    "from hyperfast import HyperFastClassifier\n",
    "\n",
    "import warnings\n",
    "max_times = [1]\n",
    "device = \"cuda:3\"\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_gd_gpu_no_learn_default on cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 745/745 [00:01<00:00, 402.91it/s]\n"
     ]
    }
   ],
   "source": [
    "max_times = [15]\n",
    "clf_dict= {\n",
    "    'mothernet_gd_gpu_no_learn_default': mothernet_init_metric}\n",
    "\n",
    "results_mlp = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_valid_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, n_jobs=1, device=\"cuda:1\", verbose=0)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_gd_gpu4 on cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 745/745 [00:01<00:00, 404.27it/s]\n"
     ]
    }
   ],
   "source": [
    "max_times = [1]\n",
    "clf_dict= {\n",
    "    'mothernet_gd_gpu4': mothernet_init_metric}\n",
    "\n",
    "results_mothernet_gd = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_valid_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, n_jobs=1, device=\"cuda:1\", verbose=0)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mlp_gpu2 on cuda:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██████████▉                                                                                                                                                                                                                                                                                                                                        | 24/745 [00:00<00:03, 224.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating breast-cancer with 286 samples\n",
      "Evaluating breast-cancer with 286 samples\n",
      "Evaluating breast-cancer with 286 samples\n",
      "Evaluating breast-cancer with 286 samples\n",
      "Evaluating breast-cancer with 286 samples\n",
      "Evaluating colic with 368 samples\n",
      "Evaluating colic with 368 samples\n",
      "Evaluating colic with 368 samples\n",
      "Evaluating colic with 368 samples\n",
      "Evaluating colic with 368 samples\n",
      "Evaluating dermatology with 366 samples\n",
      "Evaluating dermatology with 366 samples\n",
      "Evaluating dermatology with 366 samples\n",
      "Evaluating dermatology with 366 samples\n",
      "Evaluating dermatology with 366 samples\n",
      "Evaluating sonar with 208 samples\n",
      "Evaluating sonar with 208 samples\n",
      "Evaluating sonar with 208 samples\n",
      "Evaluating sonar with 208 samples\n",
      "Evaluating sonar with 208 samples\n",
      "Evaluating glass with 214 samples\n",
      "Evaluating glass with 214 samples\n",
      "Evaluating glass with 214 samples\n",
      "Evaluating glass with 214 samples\n",
      "Evaluating glass with 214 samples\n",
      "Evaluating haberman with 306 samples\n",
      "Evaluating haberman with 306 samples\n",
      "Evaluating haberman with 306 samples\n",
      "Evaluating haberman with 306 samples\n",
      "Evaluating haberman with 306 samples\n",
      "Evaluating tae with 151 samples\n",
      "Evaluating tae with 151 samples\n",
      "Evaluating tae with 151 samples\n",
      "Evaluating tae with 151 samples\n",
      "Evaluating tae with 151 samples\n",
      "Evaluating heart-c with 303 samples\n",
      "Evaluating heart-c with 303 samples\n",
      "Evaluating heart-c with 303 samples\n",
      "Evaluating heart-c with 303 samples\n",
      "Evaluating heart-c with 303 samples\n",
      "Evaluating heart-h with 294 samples\n",
      "Evaluating heart-h with 294 samples\n",
      "Evaluating heart-h with 294 samples\n",
      "Evaluating heart-h with 294 samples\n",
      "Evaluating heart-h with 294 samples\n",
      "Evaluating heart-statlog with 270 samples\n",
      "Evaluating heart-statlog with 270 samples\n",
      "Evaluating heart-statlog with 270 samples\n",
      "Evaluating heart-statlog with 270 samples\n",
      "Evaluating heart-statlog with 270 samples\n",
      "Evaluating hepatitis with 155 samples\n",
      "Evaluating hepatitis with 155 samples\n",
      "Evaluating hepatitis with 155 samples\n",
      "Evaluating hepatitis with 155 samples\n",
      "Evaluating hepatitis with 155 samples\n",
      "Evaluating vote with 435 samples\n",
      "Evaluating vote with 435 samples\n",
      "Evaluating vote with 435 samples\n",
      "Evaluating vote with 435 samples\n",
      "Evaluating vote with 435 samples\n",
      "Evaluating ionosphere with 351 samples\n",
      "Evaluating ionosphere with 351 samples\n",
      "Evaluating ionosphere with 351 samples\n",
      "Evaluating ionosphere with 351 samples\n",
      "Evaluating ionosphere with 351 samples\n",
      "Evaluating iris with 150 samples\n",
      "Evaluating iris with 150 samples\n",
      "Evaluating iris with 150 samples\n",
      "Evaluating iris with 150 samples\n",
      "Evaluating iris with 150 samples\n",
      "Evaluating wine with 178 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████████████████████████████████▊                                                                                                                                                                                                                                                                                               | 112/745 [00:00<00:01, 368.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating wine with 178 samples\n",
      "Evaluating wine with 178 samples\n",
      "Evaluating wine with 178 samples\n",
      "Evaluating wine with 178 samples\n",
      "Evaluating hayes-roth with 160 samples\n",
      "Evaluating hayes-roth with 160 samples\n",
      "Evaluating hayes-roth with 160 samples\n",
      "Evaluating hayes-roth with 160 samples\n",
      "Evaluating hayes-roth with 160 samples\n",
      "Evaluating monks-problems-1 with 556 samples\n",
      "Evaluating monks-problems-1 with 556 samples\n",
      "Evaluating monks-problems-1 with 556 samples\n",
      "Evaluating monks-problems-1 with 556 samples\n",
      "Evaluating monks-problems-1 with 556 samples\n",
      "Evaluating monks-problems-2 with 601 samples\n",
      "Evaluating monks-problems-2 with 601 samples\n",
      "Evaluating monks-problems-2 with 601 samples\n",
      "Evaluating monks-problems-2 with 601 samples\n",
      "Evaluating monks-problems-2 with 601 samples\n",
      "Evaluating monks-problems-3 with 554 samples\n",
      "Evaluating monks-problems-3 with 554 samples\n",
      "Evaluating monks-problems-3 with 554 samples\n",
      "Evaluating monks-problems-3 with 554 samples\n",
      "Evaluating monks-problems-3 with 554 samples\n",
      "Evaluating SPECT with 267 samples\n",
      "Evaluating SPECT with 267 samples\n",
      "Evaluating SPECT with 267 samples\n",
      "Evaluating SPECT with 267 samples\n",
      "Evaluating SPECT with 267 samples\n",
      "Evaluating SPECTF with 349 samples\n",
      "Evaluating SPECTF with 349 samples\n",
      "Evaluating SPECTF with 349 samples\n",
      "Evaluating SPECTF with 349 samples\n",
      "Evaluating SPECTF with 349 samples\n",
      "Evaluating grub-damage with 155 samples\n",
      "Evaluating grub-damage with 155 samples\n",
      "Evaluating grub-damage with 155 samples\n",
      "Evaluating grub-damage with 155 samples\n",
      "Evaluating grub-damage with 155 samples\n",
      "Evaluating synthetic_control with 600 samples\n",
      "Evaluating synthetic_control with 600 samples\n",
      "Evaluating synthetic_control with 600 samples\n",
      "Evaluating synthetic_control with 600 samples\n",
      "Evaluating synthetic_control with 600 samples\n",
      "Evaluating prnn_crabs with 200 samples\n",
      "Evaluating prnn_crabs with 200 samples\n",
      "Evaluating prnn_crabs with 200 samples\n",
      "Evaluating prnn_crabs with 200 samples\n",
      "Evaluating prnn_crabs with 200 samples\n",
      "Evaluating analcatdata_lawsuit with 264 samples\n",
      "Evaluating analcatdata_lawsuit with 264 samples\n",
      "Evaluating analcatdata_lawsuit with 264 samples\n",
      "Evaluating analcatdata_lawsuit with 264 samples\n",
      "Evaluating analcatdata_lawsuit with 264 samples\n",
      "Evaluating irish with 500 samples\n",
      "Evaluating irish with 500 samples\n",
      "Evaluating irish with 500 samples\n",
      "Evaluating irish with 500 samples\n",
      "Evaluating irish with 500 samples\n",
      "Evaluating analcatdata_broadwaymult with 285 samples\n",
      "Evaluating analcatdata_broadwaymult with 285 samples\n",
      "Evaluating analcatdata_broadwaymult with 285 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                              | 149/745 [00:00<00:02, 290.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating analcatdata_broadwaymult with 285 samples\n",
      "Evaluating analcatdata_broadwaymult with 285 samples\n",
      "Evaluating analcatdata_reviewer with 379 samples\n",
      "Evaluating analcatdata_reviewer with 379 samples\n",
      "Evaluating analcatdata_reviewer with 379 samples\n",
      "Evaluating analcatdata_reviewer with 379 samples\n",
      "Evaluating analcatdata_reviewer with 379 samples\n",
      "Evaluating backache with 180 samples\n",
      "Evaluating backache with 180 samples\n",
      "Evaluating backache with 180 samples\n",
      "Evaluating backache with 180 samples\n",
      "Evaluating backache with 180 samples\n",
      "Evaluating prnn_synth with 250 samples\n",
      "Evaluating prnn_synth with 250 samples\n",
      "Evaluating prnn_synth with 250 samples\n",
      "Evaluating prnn_synth with 250 samples\n",
      "Evaluating prnn_synth with 250 samples\n",
      "Evaluating schizo with 340 samples\n",
      "Evaluating schizo with 340 samples\n",
      "Evaluating schizo with 340 samples\n",
      "Evaluating schizo with 340 samples\n",
      "Evaluating schizo with 340 samples\n",
      "Evaluating profb with 672 samples\n",
      "Evaluating profb with 672 samples\n",
      "Evaluating profb with 672 samples\n",
      "Evaluating profb with 672 samples\n",
      "Evaluating profb with 672 samples\n",
      "Evaluating analcatdata_germangss with 400 samples\n",
      "Evaluating analcatdata_germangss with 400 samples\n",
      "Evaluating analcatdata_germangss with 400 samples\n",
      "Evaluating analcatdata_germangss with 400 samples\n",
      "Evaluating analcatdata_germangss with 400 samples\n",
      "Evaluating biomed with 209 samples\n",
      "Evaluating biomed with 209 samples\n",
      "Evaluating biomed with 209 samples\n",
      "Evaluating biomed with 209 samples\n",
      "Evaluating biomed with 209 samples\n",
      "Evaluating rmftsa_sleepdata with 1024 samples\n",
      "Evaluating rmftsa_sleepdata with 1024 samples\n",
      "Evaluating rmftsa_sleepdata with 1024 samples\n",
      "Evaluating rmftsa_sleepdata with 1024 samples\n",
      "Evaluating rmftsa_sleepdata with 1024 samples\n",
      "Evaluating diggle_table_a2 with 310 samples\n",
      "Evaluating diggle_table_a2 with 310 samples\n",
      "Evaluating diggle_table_a2 with 310 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                                                                | 251/745 [00:00<00:01, 345.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating diggle_table_a2 with 310 samples\n",
      "Evaluating diggle_table_a2 with 310 samples\n",
      "Evaluating rmftsa_ladata with 508 samples\n",
      "Evaluating rmftsa_ladata with 508 samples\n",
      "Evaluating rmftsa_ladata with 508 samples\n",
      "Evaluating rmftsa_ladata with 508 samples\n",
      "Evaluating rmftsa_ladata with 508 samples\n",
      "Evaluating pwLinear with 200 samples\n",
      "Evaluating pwLinear with 200 samples\n",
      "Evaluating pwLinear with 200 samples\n",
      "Evaluating pwLinear with 200 samples\n",
      "Evaluating pwLinear with 200 samples\n",
      "Evaluating analcatdata_vineyard with 468 samples\n",
      "Evaluating analcatdata_vineyard with 468 samples\n",
      "Evaluating analcatdata_vineyard with 468 samples\n",
      "Evaluating analcatdata_vineyard with 468 samples\n",
      "Evaluating analcatdata_vineyard with 468 samples\n",
      "Evaluating machine_cpu with 209 samples\n",
      "Evaluating machine_cpu with 209 samples\n",
      "Evaluating machine_cpu with 209 samples\n",
      "Evaluating machine_cpu with 209 samples\n",
      "Evaluating machine_cpu with 209 samples\n",
      "Evaluating pharynx with 195 samples\n",
      "Evaluating pharynx with 195 samples\n",
      "Evaluating pharynx with 195 samples\n",
      "Evaluating pharynx with 195 samples\n",
      "Evaluating pharynx with 195 samples\n",
      "Evaluating auto_price with 159 samples\n",
      "Evaluating auto_price with 159 samples\n",
      "Evaluating auto_price with 159 samples\n",
      "Evaluating auto_price with 159 samples\n",
      "Evaluating auto_price with 159 samples\n",
      "Evaluating servo with 167 samples\n",
      "Evaluating servo with 167 samples\n",
      "Evaluating servo with 167 samples\n",
      "Evaluating servo with 167 samples\n",
      "Evaluating servo with 167 samples\n",
      "Evaluating analcatdata_wildcat with 163 samples\n",
      "Evaluating analcatdata_wildcat with 163 samples\n",
      "Evaluating analcatdata_wildcat with 163 samples\n",
      "Evaluating analcatdata_wildcat with 163 samples\n",
      "Evaluating analcatdata_wildcat with 163 samples\n",
      "Evaluating pm10 with 500 samples\n",
      "Evaluating pm10 with 500 samples\n",
      "Evaluating pm10 with 500 samples\n",
      "Evaluating pm10 with 500 samples\n",
      "Evaluating pm10 with 500 samples\n",
      "Evaluating wisconsin with 194 samples\n",
      "Evaluating wisconsin with 194 samples\n",
      "Evaluating wisconsin with 194 samples\n",
      "Evaluating wisconsin with 194 samples\n",
      "Evaluating wisconsin with 194 samples\n",
      "Evaluating autoPrice with 159 samples\n",
      "Evaluating autoPrice with 159 samples\n",
      "Evaluating autoPrice with 159 samples\n",
      "Evaluating autoPrice with 159 samples\n",
      "Evaluating autoPrice with 159 samples\n",
      "Evaluating meta with 528 samples\n",
      "Evaluating meta with 528 samples\n",
      "Evaluating meta with 528 samples\n",
      "Evaluating meta with 528 samples\n",
      "Evaluating meta with 528 samples\n",
      "Evaluating analcatdata_apnea3 with 450 samples\n",
      "Evaluating analcatdata_apnea3 with 450 samples\n",
      "Evaluating analcatdata_apnea3 with 450 samples\n",
      "Evaluating analcatdata_apnea3 with 450 samples\n",
      "Evaluating analcatdata_apnea3 with 450 samples\n",
      "Evaluating analcatdata_apnea2 with 475 samples\n",
      "Evaluating analcatdata_apnea2 with 475 samples\n",
      "Evaluating analcatdata_apnea2 with 475 samples\n",
      "Evaluating analcatdata_apnea2 with 475 samples\n",
      "Evaluating analcatdata_apnea2 with 475 samples\n",
      "Evaluating analcatdata_apnea1 with 475 samples\n",
      "Evaluating analcatdata_apnea1 with 475 samples\n",
      "Evaluating analcatdata_apnea1 with 475 samples\n",
      "Evaluating analcatdata_apnea1 with 475 samples\n",
      "Evaluating analcatdata_apnea1 with 475 samples\n",
      "Evaluating disclosure_x_bias with 662 samples\n",
      "Evaluating disclosure_x_bias with 662 samples\n",
      "Evaluating disclosure_x_bias with 662 samples\n",
      "Evaluating disclosure_x_bias with 662 samples\n",
      "Evaluating disclosure_x_bias with 662 samples\n",
      "Evaluating bodyfat with 252 samples\n",
      "Evaluating bodyfat with 252 samples\n",
      "Evaluating bodyfat with 252 samples\n",
      "Evaluating bodyfat with 252 samples\n",
      "Evaluating bodyfat with 252 samples\n",
      "Evaluating cleveland with 303 samples\n",
      "Evaluating cleveland with 303 samples\n",
      "Evaluating cleveland with 303 samples\n",
      "Evaluating cleveland with 303 samples\n",
      "Evaluating cleveland with 303 samples\n",
      "Evaluating triazines with 186 samples\n",
      "Evaluating triazines with 186 samples\n",
      "Evaluating triazines with 186 samples\n",
      "Evaluating triazines with 186 samples\n",
      "Evaluating triazines with 186 samples\n",
      "Evaluating disclosure_x_tampered with 662 samples\n",
      "Evaluating disclosure_x_tampered with 662 samples\n",
      "Evaluating disclosure_x_tampered with 662 samples\n",
      "Evaluating disclosure_x_tampered with 662 samples\n",
      "Evaluating disclosure_x_tampered with 662 samples\n",
      "Evaluating cpu with 209 samples\n",
      "Evaluating cpu with 209 samples\n",
      "Evaluating cpu with 209 samples\n",
      "Evaluating cpu with 209 samples\n",
      "Evaluating cpu with 209 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                               | 393/745 [00:00<00:00, 515.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating cholesterol with 303 samples\n",
      "Evaluating cholesterol with 303 samples\n",
      "Evaluating cholesterol with 303 samples\n",
      "Evaluating cholesterol with 303 samples\n",
      "Evaluating cholesterol with 303 samples\n",
      "Evaluating chscase_funds with 185 samples\n",
      "Evaluating chscase_funds with 185 samples\n",
      "Evaluating chscase_funds with 185 samples\n",
      "Evaluating chscase_funds with 185 samples\n",
      "Evaluating chscase_funds with 185 samples\n",
      "Evaluating pbcseq with 1945 samples\n",
      "Evaluating pbcseq with 1945 samples\n",
      "Evaluating pbcseq with 1945 samples\n",
      "Evaluating pbcseq with 1945 samples\n",
      "Evaluating pbcseq with 1945 samples\n",
      "Evaluating pbc with 418 samples\n",
      "Evaluating pbc with 418 samples\n",
      "Evaluating pbc with 418 samples\n",
      "Evaluating pbc with 418 samples\n",
      "Evaluating pbc with 418 samples\n",
      "Evaluating rmftsa_ctoarrivals with 264 samples\n",
      "Evaluating rmftsa_ctoarrivals with 264 samples\n",
      "Evaluating rmftsa_ctoarrivals with 264 samples\n",
      "Evaluating rmftsa_ctoarrivals with 264 samples\n",
      "Evaluating rmftsa_ctoarrivals with 264 samples\n",
      "Evaluating chscase_vine2 with 468 samples\n",
      "Evaluating chscase_vine2 with 468 samples\n",
      "Evaluating chscase_vine2 with 468 samples\n",
      "Evaluating chscase_vine2 with 468 samples\n",
      "Evaluating chscase_vine2 with 468 samples\n",
      "Evaluating chatfield_4 with 235 samples\n",
      "Evaluating chatfield_4 with 235 samples\n",
      "Evaluating chatfield_4 with 235 samples\n",
      "Evaluating chatfield_4 with 235 samples\n",
      "Evaluating chatfield_4 with 235 samples\n",
      "Evaluating boston_corrected with 506 samples\n",
      "Evaluating boston_corrected with 506 samples\n",
      "Evaluating boston_corrected with 506 samples\n",
      "Evaluating boston_corrected with 506 samples\n",
      "Evaluating boston_corrected with 506 samples\n",
      "Evaluating sensory with 576 samples\n",
      "Evaluating sensory with 576 samples\n",
      "Evaluating sensory with 576 samples\n",
      "Evaluating sensory with 576 samples\n",
      "Evaluating sensory with 576 samples\n",
      "Evaluating disclosure_x_noise with 662 samples\n",
      "Evaluating disclosure_x_noise with 662 samples\n",
      "Evaluating disclosure_x_noise with 662 samples\n",
      "Evaluating disclosure_x_noise with 662 samples\n",
      "Evaluating disclosure_x_noise with 662 samples\n",
      "Evaluating autoMpg with 398 samples\n",
      "Evaluating autoMpg with 398 samples\n",
      "Evaluating autoMpg with 398 samples\n",
      "Evaluating autoMpg with 398 samples\n",
      "Evaluating autoMpg with 398 samples\n",
      "Evaluating kdd_el_nino-small with 782 samples\n",
      "Evaluating kdd_el_nino-small with 782 samples\n",
      "Evaluating kdd_el_nino-small with 782 samples\n",
      "Evaluating kdd_el_nino-small with 782 samples\n",
      "Evaluating kdd_el_nino-small with 782 samples\n",
      "Evaluating autoHorse with 205 samples\n",
      "Evaluating autoHorse with 205 samples\n",
      "Evaluating autoHorse with 205 samples\n",
      "Evaluating autoHorse with 205 samples\n",
      "Evaluating autoHorse with 205 samples\n",
      "Evaluating stock with 950 samples\n",
      "Evaluating stock with 950 samples\n",
      "Evaluating stock with 950 samples\n",
      "Evaluating stock with 950 samples\n",
      "Evaluating stock with 950 samples\n",
      "Evaluating breastTumor with 286 samples\n",
      "Evaluating breastTumor with 286 samples\n",
      "Evaluating breastTumor with 286 samples\n",
      "Evaluating breastTumor with 286 samples\n",
      "Evaluating breastTumor with 286 samples\n",
      "Evaluating analcatdata_gsssexsurvey with 159 samples\n",
      "Evaluating analcatdata_gsssexsurvey with 159 samples\n",
      "Evaluating analcatdata_gsssexsurvey with 159 samples\n",
      "Evaluating analcatdata_gsssexsurvey with 159 samples\n",
      "Evaluating analcatdata_gsssexsurvey with 159 samples\n",
      "Evaluating boston with 506 samples\n",
      "Evaluating boston with 506 samples\n",
      "Evaluating boston with 506 samples\n",
      "Evaluating boston with 506 samples\n",
      "Evaluating boston with 506 samples\n",
      "Evaluating fishcatch with 158 samples\n",
      "Evaluating fishcatch with 158 samples\n",
      "Evaluating fishcatch with 158 samples\n",
      "Evaluating fishcatch with 158 samples\n",
      "Evaluating fishcatch with 158 samples\n",
      "Evaluating vinnie with 380 samples\n",
      "Evaluating vinnie with 380 samples\n",
      "Evaluating vinnie with 380 samples\n",
      "Evaluating vinnie with 380 samples\n",
      "Evaluating vinnie with 380 samples\n",
      "Evaluating mu284 with 284 samples\n",
      "Evaluating mu284 with 284 samples\n",
      "Evaluating mu284 with 284 samples\n",
      "Evaluating mu284 with 284 samples\n",
      "Evaluating mu284 with 284 samples\n",
      "Evaluating no2 with 500 samples\n",
      "Evaluating no2 with 500 samples\n",
      "Evaluating no2 with 500 samples\n",
      "Evaluating no2 with 500 samples\n",
      "Evaluating no2 with 500 samples\n",
      "Evaluating chscase_geyser1 with 222 samples\n",
      "Evaluating chscase_geyser1 with 222 samples\n",
      "Evaluating chscase_geyser1 with 222 samples\n",
      "Evaluating chscase_geyser1 with 222 samples\n",
      "Evaluating chscase_geyser1 with 222 samples\n",
      "Evaluating chscase_census6 with 400 samples\n",
      "Evaluating chscase_census6 with 400 samples\n",
      "Evaluating chscase_census6 with 400 samples\n",
      "Evaluating chscase_census6 with 400 samples\n",
      "Evaluating chscase_census6 with 400 samples\n",
      "Evaluating chscase_census5 with 400 samples\n",
      "Evaluating chscase_census5 with 400 samples\n",
      "Evaluating chscase_census5 with 400 samples\n",
      "Evaluating chscase_census5 with 400 samples\n",
      "Evaluating chscase_census5 with 400 samples\n",
      "Evaluating chscase_census4 with 400 samples\n",
      "Evaluating chscase_census4 with 400 samples\n",
      "Evaluating chscase_census4 with 400 samples\n",
      "Evaluating chscase_census4 with 400 samples\n",
      "Evaluating chscase_census4 with 400 samples\n",
      "Evaluating chscase_census3 with 400 samples\n",
      "Evaluating chscase_census3 with 400 samples\n",
      "Evaluating chscase_census3 with 400 samples\n",
      "Evaluating chscase_census3 with 400 samples\n",
      "Evaluating chscase_census3 with 400 samples\n",
      "Evaluating chscase_census2 with 400 samples\n",
      "Evaluating chscase_census2 with 400 samples\n",
      "Evaluating chscase_census2 with 400 samples\n",
      "Evaluating chscase_census2 with 400 samples\n",
      "Evaluating chscase_census2 with 400 samples\n",
      "Evaluating plasma_retinol with 315 samples\n",
      "Evaluating plasma_retinol with 315 samples\n",
      "Evaluating plasma_retinol with 315 samples\n",
      "Evaluating plasma_retinol with 315 samples\n",
      "Evaluating plasma_retinol with 315 samples\n",
      "Evaluating visualizing_galaxy with 323 samples\n",
      "Evaluating visualizing_galaxy with 323 samples\n",
      "Evaluating visualizing_galaxy with 323 samples\n",
      "Evaluating visualizing_galaxy with 323 samples\n",
      "Evaluating visualizing_galaxy with 323 samples\n",
      "Evaluating colleges_usnews with 1302 samples\n",
      "Evaluating colleges_usnews with 1302 samples\n",
      "Evaluating colleges_usnews with 1302 samples\n",
      "Evaluating colleges_usnews with 1302 samples\n",
      "Evaluating colleges_usnews with 1302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                              | 537/745 [00:01<00:00, 609.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating disclosure_z with 662 samples\n",
      "Evaluating disclosure_z with 662 samples\n",
      "Evaluating disclosure_z with 662 samples\n",
      "Evaluating disclosure_z with 662 samples\n",
      "Evaluating disclosure_z with 662 samples\n",
      "Evaluating socmob with 1156 samples\n",
      "Evaluating socmob with 1156 samples\n",
      "Evaluating socmob with 1156 samples\n",
      "Evaluating socmob with 1156 samples\n",
      "Evaluating socmob with 1156 samples\n",
      "Evaluating chscase_whale with 228 samples\n",
      "Evaluating chscase_whale with 228 samples\n",
      "Evaluating chscase_whale with 228 samples\n",
      "Evaluating chscase_whale with 228 samples\n",
      "Evaluating chscase_whale with 228 samples\n",
      "Evaluating water-treatment with 527 samples\n",
      "Evaluating water-treatment with 527 samples\n",
      "Evaluating water-treatment with 527 samples\n",
      "Evaluating water-treatment with 527 samples\n",
      "Evaluating water-treatment with 527 samples\n",
      "Evaluating lowbwt with 189 samples\n",
      "Evaluating lowbwt with 189 samples\n",
      "Evaluating lowbwt with 189 samples\n",
      "Evaluating lowbwt with 189 samples\n",
      "Evaluating lowbwt with 189 samples\n",
      "Evaluating arsenic-female-bladder with 559 samples\n",
      "Evaluating arsenic-female-bladder with 559 samples\n",
      "Evaluating arsenic-female-bladder with 559 samples\n",
      "Evaluating arsenic-female-bladder with 559 samples\n",
      "Evaluating arsenic-female-bladder with 559 samples\n",
      "Evaluating analcatdata_halloffame with 1340 samples\n",
      "Evaluating analcatdata_halloffame with 1340 samples\n",
      "Evaluating analcatdata_halloffame with 1340 samples\n",
      "Evaluating analcatdata_halloffame with 1340 samples\n",
      "Evaluating analcatdata_halloffame with 1340 samples\n",
      "Evaluating analcatdata_birthday with 365 samples\n",
      "Evaluating analcatdata_birthday with 365 samples\n",
      "Evaluating analcatdata_birthday with 365 samples\n",
      "Evaluating analcatdata_birthday with 365 samples\n",
      "Evaluating analcatdata_birthday with 365 samples\n",
      "Evaluating analcatdata_draft with 366 samples\n",
      "Evaluating analcatdata_draft with 366 samples\n",
      "Evaluating analcatdata_draft with 366 samples\n",
      "Evaluating analcatdata_draft with 366 samples\n",
      "Evaluating analcatdata_draft with 366 samples\n",
      "Evaluating collins with 500 samples\n",
      "Evaluating collins with 500 samples\n",
      "Evaluating collins with 500 samples\n",
      "Evaluating collins with 500 samples\n",
      "Evaluating collins with 500 samples\n",
      "Evaluating prnn_fglass with 214 samples\n",
      "Evaluating prnn_fglass with 214 samples\n",
      "Evaluating prnn_fglass with 214 samples\n",
      "Evaluating prnn_fglass with 214 samples\n",
      "Evaluating prnn_fglass with 214 samples\n",
      "Evaluating jEdit_4.2_4.3 with 369 samples\n",
      "Evaluating jEdit_4.2_4.3 with 369 samples\n",
      "Evaluating jEdit_4.2_4.3 with 369 samples\n",
      "Evaluating jEdit_4.2_4.3 with 369 samples\n",
      "Evaluating jEdit_4.2_4.3 with 369 samples\n",
      "Evaluating mc2 with 161 samples\n",
      "Evaluating mc2 with 161 samples\n",
      "Evaluating mc2 with 161 samples\n",
      "Evaluating mc2 with 161 samples\n",
      "Evaluating mc2 with 161 samples\n",
      "Evaluating mw1 with 403 samples\n",
      "Evaluating mw1 with 403 samples\n",
      "Evaluating mw1 with 403 samples\n",
      "Evaluating mw1 with 403 samples\n",
      "Evaluating mw1 with 403 samples\n",
      "Evaluating jEdit_4.0_4.2 with 274 samples\n",
      "Evaluating jEdit_4.0_4.2 with 274 samples\n",
      "Evaluating jEdit_4.0_4.2 with 274 samples\n",
      "Evaluating jEdit_4.0_4.2 with 274 samples\n",
      "Evaluating jEdit_4.0_4.2 with 274 samples\n",
      "Evaluating PopularKids with 478 samples\n",
      "Evaluating PopularKids with 478 samples\n",
      "Evaluating PopularKids with 478 samples\n",
      "Evaluating PopularKids with 478 samples\n",
      "Evaluating PopularKids with 478 samples\n",
      "Evaluating teachingAssistant with 151 samples\n",
      "Evaluating teachingAssistant with 151 samples\n",
      "Evaluating teachingAssistant with 151 samples\n",
      "Evaluating teachingAssistant with 151 samples\n",
      "Evaluating teachingAssistant with 151 samples\n",
      "Evaluating lungcancer_GSE31210 with 226 samples\n",
      "Evaluating lungcancer_GSE31210 with 226 samples\n",
      "Evaluating lungcancer_GSE31210 with 226 samples\n",
      "Evaluating lungcancer_GSE31210 with 226 samples\n",
      "Evaluating lungcancer_GSE31210 with 226 samples\n",
      "Evaluating MegaWatt1 with 253 samples\n",
      "Evaluating MegaWatt1 with 253 samples\n",
      "Evaluating MegaWatt1 with 253 samples\n",
      "Evaluating MegaWatt1 with 253 samples\n",
      "Evaluating MegaWatt1 with 253 samples\n",
      "Evaluating PizzaCutter1 with 661 samples\n",
      "Evaluating PizzaCutter1 with 661 samples\n",
      "Evaluating PizzaCutter1 with 661 samples\n",
      "Evaluating PizzaCutter1 with 661 samples\n",
      "Evaluating PizzaCutter1 with 661 samples\n",
      "Evaluating PizzaCutter3 with 1043 samples\n",
      "Evaluating PizzaCutter3 with 1043 samples\n",
      "Evaluating PizzaCutter3 with 1043 samples\n",
      "Evaluating PizzaCutter3 with 1043 samples\n",
      "Evaluating PizzaCutter3 with 1043 samples\n",
      "Evaluating CostaMadre1 with 296 samples\n",
      "Evaluating CostaMadre1 with 296 samples\n",
      "Evaluating CostaMadre1 with 296 samples\n",
      "Evaluating CostaMadre1 with 296 samples\n",
      "Evaluating CostaMadre1 with 296 samples\n",
      "Evaluating CastMetal1 with 327 samples\n",
      "Evaluating CastMetal1 with 327 samples\n",
      "Evaluating CastMetal1 with 327 samples\n",
      "Evaluating CastMetal1 with 327 samples\n",
      "Evaluating CastMetal1 with 327 samples\n",
      "Evaluating KnuggetChase3 with 194 samples\n",
      "Evaluating KnuggetChase3 with 194 samples\n",
      "Evaluating KnuggetChase3 with 194 samples\n",
      "Evaluating KnuggetChase3 with 194 samples\n",
      "Evaluating KnuggetChase3 with 194 samples\n",
      "Evaluating PieChart1 with 705 samples\n",
      "Evaluating PieChart1 with 705 samples\n",
      "Evaluating PieChart1 with 705 samples\n",
      "Evaluating PieChart1 with 705 samples\n",
      "Evaluating PieChart1 with 705 samples\n",
      "Evaluating PieChart3 with 1077 samples\n",
      "Evaluating PieChart3 with 1077 samples\n",
      "Evaluating PieChart3 with 1077 samples\n",
      "Evaluating PieChart3 with 1077 samples\n",
      "Evaluating PieChart3 with 1077 samples\n",
      "Evaluating parkinsons with 195 samples\n",
      "Evaluating parkinsons with 195 samples\n",
      "Evaluating parkinsons with 195 samples\n",
      "Evaluating parkinsons with 195 samples\n",
      "Evaluating parkinsons with 195 samples\n",
      "Evaluating planning-relax with 182 samples\n",
      "Evaluating planning-relax with 182 samples\n",
      "Evaluating planning-relax with 182 samples\n",
      "Evaluating planning-relax with 182 samples\n",
      "Evaluating planning-relax with 182 samples\n",
      "Evaluating qualitative-bankruptcy with 250 samples\n",
      "Evaluating qualitative-bankruptcy with 250 samples\n",
      "Evaluating qualitative-bankruptcy with 250 samples\n",
      "Evaluating qualitative-bankruptcy with 250 samples\n",
      "Evaluating qualitative-bankruptcy with 250 samples\n",
      "Evaluating sa-heart with 462 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 602/745 [00:01<00:00, 586.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sa-heart with 462 samples\n",
      "Evaluating sa-heart with 462 samples\n",
      "Evaluating sa-heart with 462 samples\n",
      "Evaluating sa-heart with 462 samples\n",
      "Evaluating seeds with 210 samples\n",
      "Evaluating seeds with 210 samples\n",
      "Evaluating seeds with 210 samples\n",
      "Evaluating seeds with 210 samples\n",
      "Evaluating seeds with 210 samples\n",
      "Evaluating thoracic-surgery with 470 samples\n",
      "Evaluating thoracic-surgery with 470 samples\n",
      "Evaluating thoracic-surgery with 470 samples\n",
      "Evaluating thoracic-surgery with 470 samples\n",
      "Evaluating thoracic-surgery with 470 samples\n",
      "Evaluating user-knowledge with 403 samples\n",
      "Evaluating user-knowledge with 403 samples\n",
      "Evaluating user-knowledge with 403 samples\n",
      "Evaluating user-knowledge with 403 samples\n",
      "Evaluating user-knowledge with 403 samples\n",
      "Evaluating wholesale-customers with 440 samples\n",
      "Evaluating wholesale-customers with 440 samples\n",
      "Evaluating wholesale-customers with 440 samples\n",
      "Evaluating wholesale-customers with 440 samples\n",
      "Evaluating wholesale-customers with 440 samples\n",
      "Evaluating heart-long-beach with 200 samples\n",
      "Evaluating heart-long-beach with 200 samples\n",
      "Evaluating heart-long-beach with 200 samples\n",
      "Evaluating heart-long-beach with 200 samples\n",
      "Evaluating heart-long-beach with 200 samples\n",
      "Evaluating robot-failures-lp5 with 164 samples\n",
      "Evaluating robot-failures-lp5 with 164 samples\n",
      "Evaluating robot-failures-lp5 with 164 samples\n",
      "Evaluating robot-failures-lp5 with 164 samples\n",
      "Evaluating robot-failures-lp5 with 164 samples\n",
      "Evaluating vertebra-column with 310 samples\n",
      "Evaluating vertebra-column with 310 samples\n",
      "Evaluating vertebra-column with 310 samples\n",
      "Evaluating vertebra-column with 310 samples\n",
      "Evaluating vertebra-column with 310 samples\n",
      "Evaluating Smartphone-Based_Recognition_of_Human_Activities with 180 samples\n",
      "Evaluating Smartphone-Based_Recognition_of_Human_Activities with 180 samples\n",
      "Evaluating Smartphone-Based_Recognition_of_Human_Activities with 180 samples\n",
      "Evaluating Smartphone-Based_Recognition_of_Human_Activities with 180 samples\n",
      "Evaluating Smartphone-Based_Recognition_of_Human_Activities with 180 samples\n",
      "Evaluating breast-cancer-dropped-missing-attributes-values with 277 samples\n",
      "Evaluating breast-cancer-dropped-missing-attributes-values with 277 samples\n",
      "Evaluating breast-cancer-dropped-missing-attributes-values with 277 samples\n",
      "Evaluating breast-cancer-dropped-missing-attributes-values with 277 samples\n",
      "Evaluating breast-cancer-dropped-missing-attributes-values with 277 samples\n",
      "Evaluating LED-display-domain-7digit with 500 samples\n",
      "Evaluating LED-display-domain-7digit with 500 samples\n",
      "Evaluating LED-display-domain-7digit with 500 samples\n",
      "Evaluating LED-display-domain-7digit with 500 samples\n",
      "Evaluating LED-display-domain-7digit with 500 samples\n",
      "Evaluating GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1 with 1600 samples\n",
      "Evaluating GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1 with 1600 samples\n",
      "Evaluating GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1 with 1600 samples\n",
      "Evaluating GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1 with 1600 samples\n",
      "Evaluating GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1 with 1600 samples\n",
      "Evaluating calendarDOW with 399 samples\n",
      "Evaluating calendarDOW with 399 samples\n",
      "Evaluating calendarDOW with 399 samples\n",
      "Evaluating calendarDOW with 399 samples\n",
      "Evaluating calendarDOW with 399 samples\n",
      "Evaluating corral with 160 samples\n",
      "Evaluating corral with 160 samples\n",
      "Evaluating corral with 160 samples\n",
      "Evaluating corral with 160 samples\n",
      "Evaluating corral with 160 samples\n",
      "Evaluating mofn-3-7-10 with 1324 samples\n",
      "Evaluating mofn-3-7-10 with 1324 samples\n",
      "Evaluating mofn-3-7-10 with 1324 samples\n",
      "Evaluating mofn-3-7-10 with 1324 samples\n",
      "Evaluating mofn-3-7-10 with 1324 samples\n",
      "Evaluating thyroid-new with 215 samples\n",
      "Evaluating thyroid-new with 215 samples\n",
      "Evaluating thyroid-new with 215 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 712/745 [00:01<00:00, 361.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating thyroid-new with 215 samples\n",
      "Evaluating thyroid-new with 215 samples\n",
      "Evaluating solar-flare with 315 samples\n",
      "Evaluating solar-flare with 315 samples\n",
      "Evaluating solar-flare with 315 samples\n",
      "Evaluating solar-flare with 315 samples\n",
      "Evaluating solar-flare with 315 samples\n",
      "Evaluating threeOf9 with 512 samples\n",
      "Evaluating threeOf9 with 512 samples\n",
      "Evaluating threeOf9 with 512 samples\n",
      "Evaluating threeOf9 with 512 samples\n",
      "Evaluating threeOf9 with 512 samples\n",
      "Evaluating xd6 with 973 samples\n",
      "Evaluating xd6 with 973 samples\n",
      "Evaluating xd6 with 973 samples\n",
      "Evaluating xd6 with 973 samples\n",
      "Evaluating xd6 with 973 samples\n",
      "Evaluating tokyo1 with 959 samples\n",
      "Evaluating tokyo1 with 959 samples\n",
      "Evaluating tokyo1 with 959 samples\n",
      "Evaluating tokyo1 with 959 samples\n",
      "Evaluating tokyo1 with 959 samples\n",
      "Evaluating parity5_plus_5 with 1124 samples\n",
      "Evaluating parity5_plus_5 with 1124 samples\n",
      "Evaluating parity5_plus_5 with 1124 samples\n",
      "Evaluating parity5_plus_5 with 1124 samples\n",
      "Evaluating parity5_plus_5 with 1124 samples\n",
      "Evaluating cleve with 303 samples\n",
      "Evaluating cleve with 303 samples\n",
      "Evaluating cleve with 303 samples\n",
      "Evaluating cleve with 303 samples\n",
      "Evaluating cleve with 303 samples\n",
      "Evaluating cleveland-nominal with 303 samples\n",
      "Evaluating cleveland-nominal with 303 samples\n",
      "Evaluating cleveland-nominal with 303 samples\n",
      "Evaluating cleveland-nominal with 303 samples\n",
      "Evaluating cleveland-nominal with 303 samples\n",
      "Evaluating Australian with 690 samples\n",
      "Evaluating Australian with 690 samples\n",
      "Evaluating Australian with 690 samples\n",
      "Evaluating Australian with 690 samples\n",
      "Evaluating Australian with 690 samples\n",
      "Evaluating DiabeticMellitus with 281 samples\n",
      "Evaluating DiabeticMellitus with 281 samples\n",
      "Evaluating DiabeticMellitus with 281 samples\n",
      "Evaluating DiabeticMellitus with 281 samples\n",
      "Evaluating DiabeticMellitus with 281 samples\n",
      "Evaluating conference_attendance with 246 samples\n",
      "Evaluating conference_attendance with 246 samples\n",
      "Evaluating conference_attendance with 246 samples\n",
      "Evaluating conference_attendance with 246 samples\n",
      "Evaluating conference_attendance with 246 samples\n",
      "Evaluating CPMP-2015-runtime-classification with 527 samples\n",
      "Evaluating CPMP-2015-runtime-classification with 527 samples\n",
      "Evaluating CPMP-2015-runtime-classification with 527 samples\n",
      "Evaluating CPMP-2015-runtime-classification with 527 samples\n",
      "Evaluating CPMP-2015-runtime-classification with 527 samples\n",
      "Evaluating TuningSVMs with 156 samples\n",
      "Evaluating TuningSVMs with 156 samples\n",
      "Evaluating TuningSVMs with 156 samples\n",
      "Evaluating TuningSVMs with 156 samples\n",
      "Evaluating TuningSVMs with 156 samples\n",
      "Evaluating regime_alimentaire with 202 samples\n",
      "Evaluating regime_alimentaire with 202 samples\n",
      "Evaluating regime_alimentaire with 202 samples\n",
      "Evaluating regime_alimentaire with 202 samples\n",
      "Evaluating regime_alimentaire with 202 samples\n",
      "Evaluating iris-example with 150 samples\n",
      "Evaluating iris-example with 150 samples\n",
      "Evaluating iris-example with 150 samples\n",
      "Evaluating iris-example with 150 samples\n",
      "Evaluating iris-example with 150 samples\n",
      "Evaluating Touch2 with 265 samples\n",
      "Evaluating Touch2 with 265 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 745/745 [00:01<00:00, 384.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Touch2 with 265 samples\n",
      "Evaluating Touch2 with 265 samples\n",
      "Evaluating Touch2 with 265 samples\n",
      "Evaluating penguins with 344 samples\n",
      "Evaluating penguins with 344 samples\n",
      "Evaluating penguins with 344 samples\n",
      "Evaluating penguins with 344 samples\n",
      "Evaluating penguins with 344 samples\n",
      "Evaluating titanic with 891 samples\n",
      "Evaluating titanic with 891 samples\n",
      "Evaluating titanic with 891 samples\n",
      "Evaluating titanic with 891 samples\n",
      "Evaluating titanic with 891 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP GPU\n",
    "max_times = [15]\n",
    "# these will all be evaluated on CPU because they are given as callables, which is a weird way to do it.\n",
    "clf_dict= {\n",
    "    'mlp_gpu2': mlp_metric}\n",
    "\n",
    "results_mlp = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_valid_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, n_jobs=1, device=\"cuda:3\", verbose=1)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating resnet_gpu on cuda:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1490/1490 [00:03<00:00, 394.92it/s]\n"
     ]
    }
   ],
   "source": [
    "max_times = [15, 60]\n",
    "# these will all be evaluated on CPU because they are given as callables, which is a weird way to do it.\n",
    "clf_dict= {\n",
    "    'resnet_gpu': resnet_metric}\n",
    "\n",
    "results_resnet = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_valid_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, n_jobs=1, device=\"cuda:3\", verbose=0)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating knn on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 1012 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=1)]: Done 1984 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=1)]: Done 3280 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=1)]: Done 4900 tasks      | elapsed:   11.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating rf_new_params on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 1012 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=1)]: Done 1984 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=1)]: Done 3280 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=1)]: Done 4900 tasks      | elapsed:   13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating xgb on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 1012 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=1)]: Done 1984 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=1)]: Done 3280 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=1)]: Done 4900 tasks      | elapsed:   12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating logistic on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 1012 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=1)]: Done 1984 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=1)]: Done 3280 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=1)]: Done 4900 tasks      | elapsed:   12.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mlp on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 1012 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 1984 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=1)]: Done 3280 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=1)]: Done 4900 tasks      | elapsed:   13.3s\n"
     ]
    }
   ],
   "source": [
    "max_times = [1, 5, 15, 60, 5 * 60, 15 * 60, 60* 60]\n",
    "# these will all be evaluated on CPU because they are given as callables, which is a weird way to do it.\n",
    "clf_dict= {\n",
    "    'knn': knn_metric,\n",
    "    'rf_new_params': random_forest_metric,\n",
    "    'xgb': xgb_metric,\n",
    "    'logistic': logistic_metric,\n",
    "    'mlp': mlp_metric}\n",
    "\n",
    "results_baselines = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_valid_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, n_jobs=1)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EnsembleMeta.__init__() got an unexpected keyword argument 'always_quantile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8 \u001b[38;5;241m=\u001b[39m EnsembleMeta(MotherNetClassifier(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_no_power \u001b[38;5;241m=\u001b[39m EnsembleMeta(MotherNetClassifier(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, power\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_quantile \u001b[38;5;241m=\u001b[39m \u001b[43mEnsembleMeta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMotherNetClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monehot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_quantile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_3_quantile \u001b[38;5;241m=\u001b[39m EnsembleMeta(MotherNetClassifier(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, power\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, always_quantile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8_quantile \u001b[38;5;241m=\u001b[39m EnsembleMeta(MotherNetClassifier(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models_diff/mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290.cpkt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, power\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, always_quantile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: EnsembleMeta.__init__() got an unexpected keyword argument 'always_quantile'"
     ]
    }
   ],
   "source": [
    "from ticl.evaluation.tabular_evaluation import eval_on_datasets\n",
    "from ticl.prediction.mothernet import ShiftClassifier, EnsembleMeta, MotherNetClassifier, MotherNetInitMLPClassifier\n",
    "from ticl.prediction.mothernet_additive import MotherNetAdditiveClassifier\n",
    "from ticl.evaluation.baselines.distill_mlp import DistilledTabPFNMLP\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from functools import partial\n",
    "from hyperfast import HyperFastClassifier\n",
    "\n",
    "import warnings\n",
    "max_times = [1]\n",
    "device = \"cuda:3\"\n",
    "#device = \"cpu\"\n",
    "\n",
    "model_string = \"tabpfn_nooptimizer_emsize_512_nlayers_12_steps_2048_bs_32ada_lr_0.0001_1_gpu_07_24_2023_01_43_33\"\n",
    "tabpfn_ours = TabPFNClassifier(device=device, model_string=model_string, epoch=\"1650\", N_ensemble_configurations=3)\n",
    "mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_no_power = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\", device=device), n_estimators=8, onehot=True, power=False)\n",
    "mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_quantile = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\", device=device), n_estimators=8, onehot=True, power=False, always_quantile=True)\n",
    "mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_3_quantile = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\", device=device), n_estimators=3, onehot=True, power=False, always_quantile=True)\n",
    "\n",
    "mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8_quantile = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290.cpkt\", device=device), n_estimators=8, onehot=True, power=False, always_quantile=True)\n",
    "mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290.cpkt\", device=device), n_estimators=8, onehot=True, power=True, always_quantile=False)\n",
    "mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_quantile_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290.cpkt\", device=device), n_estimators=8, onehot=True, power='quantile')\n",
    "mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_quantile_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\", device=device), n_estimators=8, onehot=True, power='quantile')\n",
    "\n",
    "mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060_ohe_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_categoricalfeaturep0.9_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060.cpkt\", device=device), n_estimators=8, onehot=True, power=True)\n",
    "mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060_ohe_quantile_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_categoricalfeaturep0.9_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060.cpkt\", device=device), n_estimators=8, onehot=True, power=\"quantile\")\n",
    "\n",
    "mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490_ohe_quantile_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490.cpkt\", device=device), n_estimators=8, onehot=True, power=\"quantile\")\n",
    "mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490_ohe_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "\n",
    "\n",
    "mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1270_ohe_quantile_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_categoricalfeaturep0.9_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1270.cpkt\", device=device), n_estimators=8, onehot=True, power=\"quantile\")\n",
    "\n",
    "\n",
    "mlp_distill = make_pipeline(StandardScaler(), DistilledTabPFNMLP(n_epochs=1000, device=device, hidden_size=128, n_layers=2, dropout_rate=.1, learning_rate=0.01, model_string=model_string, epoch=1650, N_ensemble_configurations=3))\n",
    "mothernet_21_46_25_3940_ensemble3 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_d2048_H4096_L2_W32_P512_1_gpu_warm_08_25_2023_21_46_25_epoch_3940_no_optimizer.pickle\", device=device), n_estimators=3)\n",
    "ebm_bins_main_effects = ExplainableBoostingClassifier(max_bins=64, interactions=0)\n",
    "baam_nfeatures_20_no_ensemble_e1520 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_1520.cpkt\", device=device)\n",
    "\n",
    "clf_dict= {\n",
    "    'mothernet': partial(transformer_metric, classifier=mothernet_21_46_25_3940_ensemble3, onehot=True),\n",
    "    'mlp_distill': mlp_distill,\n",
    "    'tabpfn': transformer_metric,\n",
    "    #'tabpfn_ours': tabpfn_ours,\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"hyperfast_no_optimize_gpu\": partial(hyperfast_metric, optimization=None),\n",
    "    \"hyperfast_defaults_gpu\": hyperfast_metric,\n",
    "    #'ebm_bins_main_effects': ebm_bins_main_effects,\n",
    "    #'baam_nfeatures_20_no_ensemble_e1520': baam_nfeatures_20_no_ensemble_e1520,\n",
    "    'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8': mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8,\n",
    "    'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_no_power': mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_no_power,\n",
    "    'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_quantile2':mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8,\n",
    "    'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_quantile': mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_quantile,\n",
    "    'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_3_quantile': mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_3_quantile,\n",
    "    'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8_quantile': mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8_quantile,\n",
    "    'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8': mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8,\n",
    "    'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_quantile_8_fixed2': mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_quantile_8,\n",
    "    'mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060_ohe_8': mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060_ohe_8,\n",
    "    'mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060_ohe_quantile_8_fixed2': mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060_ohe_quantile_8,\n",
    "    'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490_ohe_quantile_8': mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490_ohe_quantile_8,\n",
    "    'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490_ohe_8': mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490_ohe_8,\n",
    "    'mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1270_ohe_quantile_8': mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1270_ohe_quantile_8,\n",
    "\n",
    "    }\n",
    "results_transformers = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_valid_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, overwrite=False, n_jobs=-1, device=device)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mlp_distill on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating tabpfn on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating tabpfn on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating tabpfn_ours on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating tabpfn_ours_ensemble_8 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating tabpfn_ours_ensemble_32 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_init_gd on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_init_gd_no_learning on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_init_gd_epochs_10 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_init_gd_epochs_10_lr0001 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_init_gd_no_learning_ohe on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_init_gd_ohe on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45_e630 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45_e1130 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ebm_default on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ebm_bins_main_effects on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mn_Dclass_average_03_25_2024_17_14_32_epoch_3970_ohe_ensemble_8 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mn_Dclass_average_02_29_2024_04_16_00_ohe_ensemble_8 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_categoricalfeaturep09_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_15_2024_20_58_13_epoch_280 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_categoricalembeddingTrue_categoricalfeaturep09_l1e05_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_17_2024_00_02_36_epoch_230 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mn_Dclass_average_fourierfeatures16_05_09_2024_01_03_23_epoch_100 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    1.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1490 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1780 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_nsamples500_numfeatures20_04_04_2024_03_07_12_epoch_1210 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating additive_Dclass_average_02_29_2024_04_15_55_epoch_1050 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_e128_nsamples500_numfeatures20_04_01_2024_15_38_54_epoch_2220 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_550 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    1.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_nfeatures_20_no_ensemble_e1210 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_nfeatures_20_no_ensemble_e1520 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_nfeatures_20_no_ensemble_e1970 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_nsamples500_numfeatures20_03_27_2024_17_57_59_epoch_470 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_1230 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_410 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_1430 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 out of 745 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 745 out of 745 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "from ticl.evaluation.tabular_evaluation import eval_on_datasets\n",
    "from ticl.prediction.mothernet import ShiftClassifier, EnsembleMeta, MotherNetClassifier, MotherNetInitMLPClassifier\n",
    "from ticl.prediction.mothernet_additive import MotherNetAdditiveClassifier\n",
    "from ticl.evaluation.baselines.distill_mlp import DistilledTabPFNMLP\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from functools import partial\n",
    "from hyperfast import HyperFastClassifier\n",
    "\n",
    "# transformers don't have max times\n",
    "max_times = [1]\n",
    "device = \"cpu\"\n",
    "\n",
    "tabpfn_ours = TabPFNClassifier(device=device, model_string=\"tabpfn_nooptimizer_emsize_512_nlayers_12_steps_2048_bs_32ada_lr_0.0001_1_gpu_07_24_2023_01_43_33\", epoch=\"1650\", N_ensemble_configurations=3)\n",
    "\n",
    "tabpfn_ours_ensemble_8 = TabPFNClassifier(device=device, model_string=\"tabpfn_nooptimizer_emsize_512_nlayers_12_steps_2048_bs_32ada_lr_0.0001_1_gpu_07_24_2023_01_43_33\", epoch=\"1650\", N_ensemble_configurations=8)\n",
    "tabpfn_ours_ensemble_32 = TabPFNClassifier(device=device, model_string=\"tabpfn_nooptimizer_emsize_512_nlayers_12_steps_2048_bs_32ada_lr_0.0001_1_gpu_07_24_2023_01_43_33\", epoch=\"1650\", N_ensemble_configurations=32)\n",
    "\n",
    "batapfn_no_ensemble = TabPFNClassifier(device=device, model_string=\"batabpfn_e128_inputembeddingfourier_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_11_35\", epoch=\"330\", N_ensemble_configurations=1)\n",
    "batapfn_no_ensemble_e410 = TabPFNClassifier(device=device, model_string=\"batabpfn_e128_inputembeddingfourier_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_11_35\", epoch=\"410\", N_ensemble_configurations=1)\n",
    "batapfn_no_ensemble_e530 = TabPFNClassifier(device=device, model_string=\"batabpfn_e128_inputembeddingfourier_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_11_35\", epoch=\"530\", N_ensemble_configurations=1)\n",
    "batapfn_no_ensemble_exit = TabPFNClassifier(device=device, model_string=\"batabpfn_e128_inputembeddingfourier_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_11_35\", epoch=\"on_exit\", N_ensemble_configurations=1)\n",
    "\n",
    "\n",
    "batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45_e630 = TabPFNClassifier(device=device, model_string=\"batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45\", epoch=\"630\", N_ensemble_configurations=1)\n",
    "batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45_e1130 = TabPFNClassifier(device=device, model_string=\"batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45\", epoch=\"1130\", N_ensemble_configurations=1)\n",
    "\n",
    "\n",
    "mlp_distill = make_pipeline(StandardScaler(), DistilledTabPFNMLP(n_epochs=1000, device=device, hidden_size=128, n_layers=2, dropout_rate=.1, learning_rate=0.01, model_string=\"tabpfn_nooptimizer_emsize_512_nlayers_12_steps_2048_bs_32ada_lr_0.0001_1_gpu_07_24_2023_01_43_33\", epoch=1650, N_ensemble_configurations=3))\n",
    "mothernet_21_46_25_3940_ensemble3 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_d2048_H4096_L2_W32_P512_1_gpu_warm_08_25_2023_21_46_25_epoch_3940_no_optimizer.pickle\", device=device), n_estimators=3)\n",
    "\n",
    "mothernet_init_gd = MotherNetInitMLPClassifier(path=\"../models_diff/mn_d2048_H4096_L2_W32_P512_1_gpu_warm_08_25_2023_21_46_25_epoch_3940_no_optimizer.pickle\", device=device, n_epochs=100)\n",
    "mothernet_init_gd_no_learning = MotherNetInitMLPClassifier(path=\"../models_diff/mn_d2048_H4096_L2_W32_P512_1_gpu_warm_08_25_2023_21_46_25_epoch_3940_no_optimizer.pickle\", device=device, n_epochs=1, learning_rate=0.0)\n",
    "mothernet_init_gd_epochs_10 = MotherNetInitMLPClassifier(path=\"../models_diff/mn_d2048_H4096_L2_W32_P512_1_gpu_warm_08_25_2023_21_46_25_epoch_3940_no_optimizer.pickle\", device=device, n_epochs=10, learning_rate=0.001, verbose=10)\n",
    "mothernet_init_gd_epochs_10_lr0001 = MotherNetInitMLPClassifier(path=\"../models_diff/mn_d2048_H4096_L2_W32_P512_1_gpu_warm_08_25_2023_21_46_25_epoch_3940_no_optimizer.pickle\", device=device, n_epochs=10, learning_rate=0.0001, verbose=10)\n",
    "\n",
    "\n",
    "mn_P512_SFalse_L2_1_gpu_01_24_2024 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_P512_SFalse_L2_1_gpu_01_24_2024_00_31_59_epoch_3950.cpkt\", device=device), n_estimators=3)\n",
    "mn_SFalse_L2_1_gpu_01_25_2024_21_20_32 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_SFalse_L2_1_gpu_01_25_2024_21_20_32_epoch_4000.cpkt\", device=device), n_estimators=3)\n",
    "mn_Dclass_average_02_29_2024_04_16_00 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_02_29_2024_04_16_00_epoch_4000.cpkt\", device=device), n_estimators=3)\n",
    "mn_Dclass_average_02_29_2024_04_16_00_ohe_ensemble = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_02_29_2024_04_16_00_epoch_4000.cpkt\", device=device), n_estimators=3, onehot=True)\n",
    "mn_Dclass_average_02_29_2024_04_16_00_ohe_ensemble_32 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_02_29_2024_04_16_00_epoch_4000.cpkt\", device=device), n_estimators=32, onehot=True)\n",
    "mn_Dclass_average_02_29_2024_04_16_00_ohe_ensemble_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_02_29_2024_04_16_00_epoch_4000.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "\n",
    "mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "\n",
    "\n",
    "mn_Dclass_average_fourierfeatures16_05_09_2024_01_03_23_epoch_100 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_fourierfeatures16_05_09_2024_01_03_23_epoch_100.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "\n",
    "\n",
    "#mn_Dclass_average_03_25_2024_17_14_32_epoch_1760_ohe_ensemble_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_1760.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "#mn_Dclass_average_03_25_2024_17_14_32_epoch_2270_ohe_ensemble_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2270.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "#mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "\n",
    "mn_Dclass_average_03_25_2024_17_14_32_epoch_3970_ohe_ensemble_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_3970.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "\n",
    "additive_1_gpu_02_14_2024_16_34_15 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_1_gpu_02_14_2024_16_34_15_epoch_950_fixed2.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "additive_step_prior_02_08_2024 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_b16_reducelronspikeTrue_multiclasstypesteps_1_gpu_02_08_2024_04_51_33_epoch_790.cpkt\", device=device), n_estimators=3, power=False)\n",
    "additive_11_08_2023 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_1_gpu_11_08_2023_23_02_58_continue_11_10_2023_03_01_40_epoch_3170_no_optimizer.cpkt\", device=device), n_estimators=3, power=False)\n",
    "additive_02_20_2024_factorized_weight_decay = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_w0.01_factorizedoutputTrue_outputrank64_1_gpu_02_20_2024_22_39_06_epoch_1260_fixed.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "additive_Dclass_average_02_29_2024_04_15_55_epoch_190 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_02_29_2024_04_15_55_epoch_190.cpkt\", device=device), n_estimators=3, power=False)\n",
    "additive_Dclass_average_02_29_2024_04_15_55_epoch_190_no_ensemble = MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_02_29_2024_04_15_55_epoch_190.cpkt\", device=device)\n",
    "additive_Dclass_average_02_29_2024_04_15_55_epoch_560 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_02_29_2024_04_15_55_epoch_560.cpkt\", device=device), n_estimators=3, power=False)\n",
    "additive_Dclass_average_02_29_2024_04_15_55_epoch_730 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_02_29_2024_04_15_55_epoch_730.cpkt\", device=device), n_estimators=3, power=False)\n",
    "additive_Dclass_average_02_29_2024_04_15_55_epoch_780 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_02_29_2024_04_15_55_epoch_780.cpkt\", device=device), n_estimators=3, power=False)\n",
    "additive_Dclass_average_02_29_2024_04_15_55_epoch_850 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_02_29_2024_04_15_55_epoch_850.cpkt\", device=device), n_estimators=3, power=False)\n",
    "additive_Dclass_average_02_29_2024_04_15_55_epoch_1050 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_02_29_2024_04_15_55_epoch_1050.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "\n",
    "additive_Dclass_average_inputlayernormTrue_02_29_2024_20_52_12_epoch_1340 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_inputlayernormTrue_02_29_2024_20_52_12_epoch_1340.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "\n",
    "\n",
    "# additive_Dclass_average_multiclassmaxsteps3_multiclasstypesteps_03_04_2024_19_04_03_epoch_100 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_multiclassmaxsteps3_multiclasstypesteps_03_04_2024_19_04_03_epoch_100.cpkt\", device=device), n_estimators=3, power=False)\n",
    "# additive_Dclass_average_multiclassmaxsteps3_multiclasstypesteps_03_04_2024_19_04_03_epoch_270 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_multiclassmaxsteps3_multiclasstypesteps_03_04_2024_19_04_03_epoch_270.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "\n",
    "# additive_H512_Dclass_average_factorizedoutputTrue_L6_03_01_2024_21_38_55_epoch_360 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_H512_Dclass_average_factorizedoutputTrue_L6_03_01_2024_21_38_55_epoch_360.cpkt\", device=device), n_estimators=3, power=False)\n",
    "# additive_Dclass_average_factorizedoutputTrue_w001_03_02_2024_02_21_10_epoch_340 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_factorizedoutputTrue_w0.01_03_02_2024_02_21_10_epoch_340.cpkt\", device=device), n_estimators=3, power=False)\n",
    "# additive_Dclass_average_factorizedoutputTrue_w001_03_02_2024_02_21_10_epoch_420 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_factorizedoutputTrue_w0.01_03_02_2024_02_21_10_epoch_420.cpkt\", device=device), n_estimators=3, power=False)\n",
    "# additive_Dclass_average_factorizedoutputTrue_w001_03_02_2024_02_21_10_epoch_1210 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_factorizedoutputTrue_w0.01_03_02_2024_02_21_10_epoch_1210.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "# additive_Dclass_average_factorizedoutputTrue_nshapefunctions128_outputrank64_shapeattentionTrue_shapeattentionheads8_03_07_2024_00_39_41_epoch_580 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_factorizedoutputTrue_nshapefunctions128_outputrank64_shapeattentionTrue_shapeattentionheads8_03_07_2024_00_39_41_epoch_580.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "# additive_Dclass_average_factorizedoutputTrue_nshapefunctions128_outputrank64_shapeattentionTrue_shapeattentionheads8_03_08_2024_21_19_43_epoch_1280 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/additive_Dclass_average_factorizedoutputTrue_nshapefunctions128_outputrank64_shapeattentionTrue_shapeattentionheads8_03_08_2024_21_19_43_epoch_1280.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "\n",
    "ebm_default = ExplainableBoostingClassifier()\n",
    "ebm_bins = ExplainableBoostingClassifier(max_bins=64)\n",
    "ebm_bins_main_effects = ExplainableBoostingClassifier(max_bins=64, interactions=0)\n",
    "\n",
    "\n",
    "baam_nfeatures_20_no_ensemble = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_400.cpkt\", device=device)\n",
    "baam_nfeatures_20_no_ensemble_e500 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_500.cpkt\", device=device)\n",
    "baam_nfeatures_20_no_ensemble_e650 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_650.cpkt\", device=device)\n",
    "baam_nfeatures_20_no_ensemble_e840 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_840.cpkt\", device=device)\n",
    "baam_nfeatures_20_no_ensemble_e1210 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_1210.cpkt\", device=device)\n",
    "baam_nfeatures_20_no_ensemble_e1520 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_1520.cpkt\", device=device)\n",
    "baam_nfeatures_20_no_ensemble_e1970 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_1970.cpkt\", device=device)\n",
    "\n",
    "\n",
    "baam_nfeatures_20 = EnsembleMeta(MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_400.cpkt\", device=device), n_estimators=3, power=False)\n",
    "\n",
    "baam_nfeatures_100_no_ensemble = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e64_nsamples500_N6_padzerosFalse_03_13_2024_20_28_36_epoch_360.cpkt\", device=device)\n",
    "\n",
    "\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_140 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_140.cpkt\", device=device)\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_150 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_150.cpkt\", device=device)\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_220 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_220.cpkt\", device=device)\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_410 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_410.cpkt\", device=device)\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_780 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_780.cpkt\", device=device)\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1010 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1010.cpkt\", device=device)\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1210 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1210.cpkt\", device=device)\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1520 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1520.cpkt\", device=device)\n",
    "baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_2940 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_2940.cpkt\", device=device)\n",
    "\n",
    "baam_nsamples500_numfeatures20_04_04_2024_03_07_12_epoch_1210 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_nsamples500_numfeatures20_04_04_2024_03_07_12_epoch_1210.cpkt\", device=device)\n",
    "\n",
    "baam_e128_nsamples500_numfeatures20_04_01_2024_15_38_54_epoch_2220 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_nsamples500_numfeatures20_04_01_2024_15_38_54_epoch_2220.cpkt\", device=device)\n",
    "\n",
    "baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1490 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1490.cpkt\", device=device)\n",
    "baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1780 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1780.cpkt\", device=device)\n",
    "\n",
    "baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_1430 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_1430.cpkt\", device=device)\n",
    "\n",
    "\n",
    "baam_categoricalembeddingTrue_nsamples500_nanbinTrue_numfeatures20_04_04_2024_14_06_39_epoch_970 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_categoricalembeddingTrue_nsamples500_nanbinTrue_numfeatures20_04_04_2024_14_06_39_epoch_970.cpkt\", device=device)\n",
    "\n",
    "baam_categoricalfeaturep09_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_15_2024_20_58_13_epoch_280 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_categoricalfeaturep0.9_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_15_2024_20_58_13_epoch_280.cpkt\", device=device)\n",
    "baam_categoricalembeddingTrue_categoricalfeaturep09_l1e05_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_17_2024_00_02_36_epoch_230 = MotherNetAdditiveClassifier(\n",
    "    path=\"../models_diff/baam_categoricalembeddingTrue_categoricalfeaturep0.9_l1e-05_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_17_2024_00_02_36_epoch_230.cpkt\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "baam_e128_nbins512_nsamples500_numfeatures20_03_19_2024_22_53_00_epoch_160 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_nbins512_nsamples500_numfeatures20_03_19_2024_22_53_00_epoch_160.cpkt\", device=device)\n",
    "\n",
    "baam_fourierfeatures64_nbins512_nsamples500_numfeatures20_03_21_2024_01_02_32_epoch_310 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_fourierfeatures64_nbins512_nsamples500_numfeatures20_03_21_2024_01_02_32_epoch_310.cpkt\", device=device)\n",
    "\n",
    "baam_marginalresidualTrue_nsamples500_numfeatures20_shapeinitzero_03_29_2024_19_20_09_epoch_130 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_marginalresidualTrue_nsamples500_numfeatures20_shapeinitzero_03_29_2024_19_20_09_epoch_130.cpkt\", device=device)\n",
    "baam_marginalresidualTrue_nsamples500_numfeatures20_shapeinitzero_03_29_2024_19_20_09_epoch_180 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_marginalresidualTrue_nsamples500_numfeatures20_shapeinitzero_03_29_2024_19_20_09_epoch_180.cpkt\", device=device)\n",
    "\n",
    "\n",
    "baam_e128_featurecurriculumTrue_nsamples500_N6_03_21_2024_17_58_54_epoch_610 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_featurecurriculumTrue_nsamples500_N6_03_21_2024_17_58_54_epoch_610.cpkt\", device=device)\n",
    "baam_e128_featurecurriculumTrue_nsamples500_N6_03_21_2024_17_58_54_epoch_660 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_e128_featurecurriculumTrue_nsamples500_N6_03_21_2024_17_58_54_epoch_660.cpkt\", device=device)\n",
    "\n",
    "baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_250 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_250.cpkt\", device=device)\n",
    "baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_1230 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_1230.cpkt\", device=device)\n",
    "\n",
    "baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_410 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_410.cpkt\", device=device)\n",
    "baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_550 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_550.cpkt\", device=device)\n",
    "baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_690 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_690.cpkt\", device=device)\n",
    "baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_890 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_890.cpkt\", device=device)\n",
    "\n",
    "baam_nsamples500_numfeatures20_03_27_2024_17_57_59_epoch_470 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_nsamples500_numfeatures20_03_27_2024_17_57_59_epoch_470.cpkt\", device=device)\n",
    "\n",
    "baam_categoricalembeddingTrue_nsamples500_nanbinTrue_numfeatures20_04_04_2024_14_06_39_epoch_190 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_categoricalembeddingTrue_nsamples500_nanbinTrue_numfeatures20_04_04_2024_14_06_39_epoch_190.cpkt\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "#hyperfast_no_optimization = HyperFastClassifier(device=device, optimization=None)\n",
    "#hyperfast_defaults = HyperFastClassifier(device=device)\n",
    "\n",
    "clf_dict= {\n",
    "    'mothernet': partial(transformer_metric, classifier=mothernet_21_46_25_3940_ensemble3, onehot=True),\n",
    "    'mlp_distill': mlp_distill,\n",
    "    'tabpfn': transformer_metric,\n",
    "    'tabpfn_ours': tabpfn_ours,\n",
    "    'tabpfn_ours_ensemble_8': tabpfn_ours_ensemble_8,\n",
    "    'tabpfn_ours_ensemble_32': tabpfn_ours_ensemble_32,\n",
    "    'mothernet_init_gd': mothernet_init_gd,\n",
    "    'mothernet_init_gd_no_learning': mothernet_init_gd_no_learning,\n",
    "    'mothernet_init_gd_epochs_10': mothernet_init_gd_epochs_10,\n",
    "    'mothernet_init_gd_epochs_10_lr0001': mothernet_init_gd_epochs_10_lr0001,\n",
    "    'mothernet_init_gd_no_learning_ohe' : partial(transformer_metric, classifier=mothernet_init_gd_no_learning, onehot=True),\n",
    "    'mothernet_init_gd_ohe' : partial(transformer_metric, classifier=mothernet_init_gd, onehot=True),\n",
    "\n",
    "\n",
    "    #'batapfn_no_ensemble': batapfn_no_ensemble,\n",
    "    #'batapfn_no_ensemble_e410': batapfn_no_ensemble_e410,\n",
    "    #'batapfn_no_ensemble_exit': batapfn_no_ensemble_exit,\n",
    "    'batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45_e630': batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45_e630,\n",
    "    'batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45_e1130': batabpfn_e256_nsamples500_numfeatures20_03_20_2024_22_14_45_e1130,\n",
    "  #\"hyperfast_no_optimize_gpu\": partial(hyperfast_metric, optimization=None),\n",
    "     \"hyperfast_no_optimize_cpu\":  partial(hyperfast_metric, optimization=None),\n",
    "    \"hyperfast_defaults_cpu\":hyperfast_metric,\n",
    "    \n",
    "    'ebm_default': partial(transformer_metric, classifier=ebm_default),\n",
    "    #'ebm_bins': partial(transformer_metric, classifier=ebm_bins),\n",
    "    'ebm_bins_main_effects': partial(transformer_metric, classifier=ebm_bins_main_effects),\n",
    "\n",
    "    'mn_Dclass_average_03_25_2024_17_14_32_epoch_3970_ohe_ensemble_8': mn_Dclass_average_03_25_2024_17_14_32_epoch_3970_ohe_ensemble_8,\n",
    "    'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8': mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8,\n",
    "    'mn_Dclass_average_02_29_2024_04_16_00_ohe_ensemble_8': mn_Dclass_average_02_29_2024_04_16_00_ohe_ensemble_8,\n",
    "    'baam_categoricalfeaturep09_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_15_2024_20_58_13_epoch_280': baam_categoricalfeaturep09_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_15_2024_20_58_13_epoch_280,\n",
    "    'baam_categoricalembeddingTrue_categoricalfeaturep09_l1e05_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_17_2024_00_02_36_epoch_230': baam_categoricalembeddingTrue_categoricalfeaturep09_l1e05_nsamples500_numfeatures20_numfeaturessamplerdouble_sample_sklearnbinningTrue_05_17_2024_00_02_36_epoch_230,\n",
    "    \n",
    "\n",
    "    'mn_Dclass_average_fourierfeatures16_05_09_2024_01_03_23_epoch_100': mn_Dclass_average_fourierfeatures16_05_09_2024_01_03_23_epoch_100,\n",
    "    \n",
    "        'baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1490': baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1490,\n",
    "   'baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1780': baam_nsamples500_numfeatures10_04_07_2024_17_04_53_epoch_1780,  #  <- TRY THIS\n",
    "    'baam_nsamples500_numfeatures20_04_04_2024_03_07_12_epoch_1210': baam_nsamples500_numfeatures20_04_04_2024_03_07_12_epoch_1210,\n",
    "\n",
    "    'additive_Dclass_average_02_29_2024_04_15_55_epoch_1050': additive_Dclass_average_02_29_2024_04_15_55_epoch_1050,\n",
    "    'baam_e128_nsamples500_numfeatures20_04_01_2024_15_38_54_epoch_2220': baam_e128_nsamples500_numfeatures20_04_01_2024_15_38_54_epoch_2220,\n",
    "    #'additive_Dclass_average_inputlayernormTrue_02_29_2024_20_52_12_epoch_1340_retry': additive_Dclass_average_inputlayernormTrue_02_29_2024_20_52_12_epoch_1340,\n",
    "    #'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_140': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_140,\n",
    "    #'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_150_redo': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_150,\n",
    "     #'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_220': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_220,\n",
    "    \n",
    "    'baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_550': baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_550,\n",
    "    # this one overfitted and then kinda recovered? but not very good in the end.\n",
    "#'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_410': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_410,\n",
    "    #'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_780': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_780,\n",
    "    #'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1010': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1010,\n",
    "    #'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1210': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1210,\n",
    "    #'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1520': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_1520,\n",
    "    #'baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_2940': baam_e128_fourierfeatures32_nsamples500_numfeatures20_03_20_2024_00_05_35_epoch_2940,\n",
    "    \n",
    "\n",
    "    #'additive_Dclass_average_multiclassmaxsteps3_multiclasstypesteps_03_04_2024_19_04_03_epoch_100': additive_Dclass_average_multiclassmaxsteps3_multiclasstypesteps_03_04_2024_19_04_03_epoch_100,\n",
    "   # 'additive_Dclass_average_multiclassmaxsteps3_multiclasstypesteps_03_04_2024_19_04_03_epoch_270': additive_Dclass_average_multiclassmaxsteps3_multiclasstypesteps_03_04_2024_19_04_03_epoch_270,\n",
    "\n",
    "  #  'additive_H512_Dclass_average_factorizedoutputTrue_L6_03_01_2024_21_38_55_epoch_360': additive_H512_Dclass_average_factorizedoutputTrue_L6_03_01_2024_21_38_55_epoch_360,\n",
    "  #  'additive_Dclass_average_factorizedoutputTrue_w001_03_02_2024_02_21_10_epoch_340': additive_Dclass_average_factorizedoutputTrue_w001_03_02_2024_02_21_10_epoch_340,\n",
    "    #'additive_Dclass_average_factorizedoutputTrue_w001_03_02_024_02_21_10_epoch_420': additive_Dclass_average_factorizedoutputTrue_w001_03_02_2024_02_21_10_epoch_420,\n",
    "    #'additive_Dclass_average_factorizedoutputTrue_w001_03_02_2024_02_21_10_epoch_1210': additive_Dclass_average_factorizedoutputTrue_w001_03_02_2024_02_21_10_epoch_1210,\n",
    "    #'additive_Dclass_average_factorizedoutputTrue_nshapefunctions128_outputrank64_shapeattentionTrue_shapeattentionheads8_03_07_2024_00_39_41_epoch_580': additive_Dclass_average_factorizedoutputTrue_nshapefunctions128_outputrank64_shapeattentionTrue_shapeattentionheads8_03_07_2024_00_39_41_epoch_580,\n",
    "    #'additive_Dclass_average_factorizedoutputTrue_nshapefunctions128_outputrank64_shapeattentionTrue_shapeattentionheads8_03_08_2024_21_19_43_epoch_1280': additive_Dclass_average_factorizedoutputTrue_nshapefunctions128_outputrank64_shapeattentionTrue_shapeattentionheads8_03_08_2024_21_19_43_epoch_1280,\n",
    "    #'baam_e128_featurecurriculumTrue_nsamples500_N6_03_21_2024_17_58_54_epoch_610': baam_e128_featurecurriculumTrue_nsamples500_N6_03_21_2024_17_58_54_epoch_610,\n",
    "    #'baam_e128_featurecurriculumTrue_nsamples500_N6_03_21_2024_17_58_54_epoch_660': baam_e128_featurecurriculumTrue_nsamples500_N6_03_21_2024_17_58_54_epoch_660,\n",
    "    # 'baam_e128_nbins512_nsamples500_numfeatures20_03_19_2024_22_53_00_epoch_160': baam_e128_nbins512_nsamples500_numfeatures20_03_19_2024_22_53_00_epoch_160,\n",
    "    # 'baam_nfeatures_20_no_ensemble': baam_nfeatures_20_no_ensemble,\n",
    "    # 'baam_nfeatures_20': baam_nfeatures_20,\n",
    "    #'baam_nfeatures_100_no_ensemble': baam_nfeatures_100_no_ensemble,\n",
    "    # 'baam_nfeatures_20_no_ensemble_e500': baam_nfeatures_20_no_ensemble_e500,\n",
    "#     'baam_nfeatures_20_no_ensemble_e650': baam_nfeatures_20_no_ensemble_e650,\n",
    "#    'baam_nfeatures_20_no_ensemble_e840': baam_nfeatures_20_no_ensemble_e840,\n",
    "    \"baam_nfeatures_20_no_ensemble_e1210\": baam_nfeatures_20_no_ensemble_e1210,\n",
    "    \"baam_nfeatures_20_no_ensemble_e1520\": baam_nfeatures_20_no_ensemble_e1520,\n",
    "    \"baam_nfeatures_20_no_ensemble_e1970\": baam_nfeatures_20_no_ensemble_e1970,\n",
    "\n",
    "    'baam_nsamples500_numfeatures20_03_27_2024_17_57_59_epoch_470': baam_nsamples500_numfeatures20_03_27_2024_17_57_59_epoch_470,\n",
    "\n",
    "    #'baam_fourierfeatures64_nbins512_nsamples500_numfeatures20_03_21_2024_01_02_32_epoch_310': baam_fourierfeatures64_nbins512_nsamples500_numfeatures20_03_21_2024_01_02_32_epoch_310,\n",
    "    #'baam_marginalresidualTrue_nsamples500_numfeatures20_shapeinitzero_03_29_2024_19_20_09_epoch_130': baam_marginalresidualTrue_nsamples500_numfeatures20_shapeinitzero_03_29_2024_19_20_09_epoch_130,\n",
    "    #    'baam_marginalresidualTrue_nsamples500_numfeatures20_shapeinitzero_03_29_2024_19_20_09_epoch_180': baam_marginalresidualTrue_nsamples500_numfeatures20_shapeinitzero_03_29_2024_19_20_09_epoch_180,\n",
    "\n",
    "#    'baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_250': baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_250,\n",
    "    'baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_1230': baam_fourierfeatures64_nsamples500_numfeatures20_03_27_2024_17_56_13_epoch_1230,\n",
    "    'baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_410': baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_410,\n",
    "#        'baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_690': baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_690,\n",
    "#    'baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_890': baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_890,\n",
    "        'baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_1430': baam_fourierfeatures64_nbins128_nsamples500_numfeatures20_03_24_2024_21_54_58_epoch_1430,\n",
    "\n",
    "    #'baam_categoricalembeddingTrue_nsamples500_nanbinTrue_numfeatures20_04_04_2024_14_06_39_epoch_970': baam_categoricalembeddingTrue_nsamples500_nanbinTrue_numfeatures20_04_04_2024_14_06_39_epoch_970,\n",
    "    #'baam_categoricalembeddingTrue_nsamples500_nanbinTrue_numfeatures20_04_04_2024_14_06_39_epoch_190': baam_categoricalembeddingTrue_nsamples500_nanbinTrue_numfeatures20_04_04_2024_14_06_39_epoch_190,\n",
    "    }\n",
    "results_transformers = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_valid_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, overwrite=False, n_jobs=-1, device=device)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flat_results = []\n",
    "for per_dataset in results_baselines + results_transformers:\n",
    "    for result in per_dataset:\n",
    "        row = {}\n",
    "        for key in ['dataset', 'model', 'mean_metric', 'split', 'max_time']:\n",
    "            row[key] = result[key]\n",
    "        best_configs_key, = [k for k in result.keys() if \"best_configs\" in k]\n",
    "        if result[best_configs_key][0] is not None:\n",
    "            row.update(result[best_configs_key][0])\n",
    "        row['mean_metric'] = float(row[\"mean_metric\"].numpy())\n",
    "        flat_results.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(flat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': 0.11869001388549805, 'inference_time': 0.044876813888549805}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['titanic_best_configs_at_1000'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['knn', 'rf_new_params', 'xgb', 'logistic', 'mlp', 'mothernet',\n",
       "       'mlp_distill', 'tabpfn', 'hyperfast_no_optimize_gpu',\n",
       "       'hyperfast_defaults_gpu',\n",
       "       'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8',\n",
       "       'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_no_power',\n",
       "       'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_quantile2',\n",
       "       'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8_quantile',\n",
       "       'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_3_quantile',\n",
       "       'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8_quantile',\n",
       "       'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_8',\n",
       "       'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1290_ohe_quantile_8_fixed2',\n",
       "       'mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060_ohe_8',\n",
       "       'mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1060_ohe_quantile_8_fixed2',\n",
       "       'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490_ohe_quantile_8',\n",
       "       'mn_Dclass_average_numfeaturessamplerdouble_sample_05_08_2024_22_58_18_epoch_1490_ohe_8',\n",
       "       'mn_categoricalfeaturep09_numfeaturessamplerdouble_sample_05_09_2024_23_39_30_epoch_1270_ohe_quantile_8'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(f\"results_validation_{datetime.date.today()}.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(results_baselines + results_transformers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df['model'] = results_df.model.replace({'knn': \"KNN\", 'rf_new_params': 'RF', 'mlp': \"MLP\",'mlp_distill': 'MLP-Distill', 'xgb':'XGBoost', 'logistic': 'LogReg',  'mothernet': 'MotherNet', 'tabpfn': 'TabPFN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/results_validation_2024-05-20.csv'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"results/results_validation_{datetime.date.today()}.csv\"\n",
    "results_df.to_csv(filename)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mothernet]",
   "language": "python",
   "name": "conda-env-mothernet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

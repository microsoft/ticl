{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datadrive/fla2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/azureuser/flash-linear-attention/fla/layers/attn.py:23: UserWarning: Flash Attention is not installed. Please install it via `pip install flash-attn --no-build-isolation`\n",
      "  warnings.warn(\"Flash Attention is not installed. Please install it via `pip install flash-attn --no-build-isolation`\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ticl.models.flash_linear_attention import FlashLinearAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_heads, seq_len, hidden_size,  = 32, 3, 2048, 9\n",
    "device, dtype = 'cuda:0', torch.bfloat16\n",
    "x = torch.randn(batch_size, seq_len, hidden_size).to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fla = FlashLinearAttention(\n",
    "    mode = 'chunk',\n",
    "    hidden_size = hidden_size,\n",
    "    expand_k = 1,\n",
    "    expand_v = 1, \n",
    "    num_heads = num_heads,\n",
    ").to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of parameters\n",
    "def get_num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_params(fla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| feature_map_q.layer1.weight | shape torch.Size([9, 9]) | number of params 81 |\n",
      "| feature_map_q.layer1.bias | shape torch.Size([9]) | number of params 9 |\n",
      "| feature_map_q.layer2.weight | shape torch.Size([9, 9]) | number of params 81 |\n",
      "| feature_map_q.layer2.bias | shape torch.Size([9]) | number of params 9 |\n",
      "| feature_map_k.layer1.weight | shape torch.Size([9, 9]) | number of params 81 |\n",
      "| feature_map_k.layer1.bias | shape torch.Size([9]) | number of params 9 |\n",
      "| feature_map_k.layer2.weight | shape torch.Size([9, 9]) | number of params 81 |\n",
      "| feature_map_k.layer2.bias | shape torch.Size([9]) | number of params 9 |\n",
      "| q_proj.weight | shape torch.Size([9, 9]) | number of params 81 |\n",
      "| k_proj.weight | shape torch.Size([9, 9]) | number of params 81 |\n",
      "| v_proj.weight | shape torch.Size([9, 9]) | number of params 81 |\n",
      "| norm.weight | shape torch.Size([3]) | number of params 3 |\n",
      "| o_proj.weight | shape torch.Size([9, 9]) | number of params 81 |\n"
     ]
    }
   ],
   "source": [
    "for name, param in fla.named_parameters():\n",
    "    print(f\"| {name} | shape {param.shape} | number of params {param.numel()} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.8030e-06, -1.9073e-06, -2.8685e-07,  ..., -1.8552e-06,\n",
       "            4.3213e-07, -9.9838e-07],\n",
       "          [ 1.3597e-07, -4.0419e-07,  9.0804e-08,  ..., -6.4448e-07,\n",
       "           -1.5348e-06, -7.2643e-08],\n",
       "          [-1.5140e-05,  1.1362e-07,  5.3644e-07,  ...,  3.0249e-06,\n",
       "           -8.0466e-07, -4.5598e-06],\n",
       "          ...,\n",
       "          [ 3.6812e-04,  8.7357e-04,  5.9891e-04,  ...,  4.5013e-04,\n",
       "           -1.4973e-04,  5.1117e-04],\n",
       "          [-3.7193e-05,  1.9646e-04, -2.6131e-04,  ..., -4.0245e-04,\n",
       "           -5.1737e-05, -1.7881e-05],\n",
       "          [-1.5163e-04,  9.5367e-05,  1.7643e-04,  ...,  8.4400e-05,\n",
       "            2.8014e-05,  5.6839e-04]],\n",
       " \n",
       "         [[ 4.1389e-04,  2.6703e-04, -7.0315e-08,  ...,  2.4033e-04,\n",
       "            4.1485e-05,  2.5392e-05],\n",
       "          [-2.5749e-04, -9.1171e-04,  3.5667e-04,  ...,  2.5177e-04,\n",
       "           -7.2956e-05, -4.1771e-04],\n",
       "          [ 8.8215e-05, -5.4932e-04, -5.4550e-04,  ..., -8.5831e-05,\n",
       "           -2.1172e-04, -3.2234e-04],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " tensor([[[[-2.0722e-08, -1.1642e-08, -3.7951e-08,  ..., -2.9977e-09,\n",
       "             4.5402e-09, -1.6516e-09],\n",
       "           [-1.1234e-08,  1.6415e-08, -1.5367e-08,  ..., -6.5484e-09,\n",
       "             2.7008e-08, -7.7416e-09],\n",
       "           [ 8.4750e-08, -2.8126e-07, -5.4133e-09,  ..., -1.6298e-07,\n",
       "            -7.9628e-08,  3.4086e-07],\n",
       "           ...,\n",
       "           [ 6.7353e-06,  1.4082e-06,  6.7651e-06,  ...,  1.1129e-07,\n",
       "            -8.0466e-06, -2.0415e-06],\n",
       "           [-8.8289e-07,  6.9141e-06, -2.8312e-06,  ..., -3.6210e-06,\n",
       "             5.2154e-07, -3.9041e-06],\n",
       "           [-5.4240e-06,  5.1260e-06, -1.0073e-05,  ...,  7.6368e-08,\n",
       "            -2.4736e-06,  4.6790e-06]]],\n",
       " \n",
       " \n",
       "         [[[-1.0848e-05,  1.8775e-06, -1.6019e-06,  ...,  3.6359e-06,\n",
       "             2.4885e-06,  1.2293e-06],\n",
       "           [-4.5598e-06,  1.0967e-05, -2.5146e-07,  ...,  2.2817e-08,\n",
       "            -5.7220e-06,  4.4517e-07],\n",
       "           [ 4.1723e-06,  1.8701e-06, -9.9838e-07,  ..., -6.9439e-06,\n",
       "            -2.4438e-06, -7.4133e-07],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        grad_fn=<ChunkLinearAttentionFunctionBackward>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fla(x[:,:(seq_len//2),:], x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BLOCK_SIZE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Launch the kernel with enough threads to exceed 'N'\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# This setup assumes launching one thread per data element\u001b[39;00m\n\u001b[1;32m     32\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m meta: (triton\u001b[38;5;241m.\u001b[39mcdiv(N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m256\u001b[39m, meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBLOCK_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m]),)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mscale_kernel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBLOCK_SIZE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/datadrive/fla2/lib/python3.10/site-packages/triton/runtime/jit.py:167\u001b[0m, in \u001b[0;36mKernelInterface.__getitem__.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, grid) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    A JIT function is launched with: fn[grid](*args, **kwargs).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    Hence JITFunction.__getitem__ returns a callable proxy that\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    memorizes the grid.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/datadrive/fla2/lib/python3.10/site-packages/triton/runtime/jit.py:380\u001b[0m, in \u001b[0;36mJITFunction.run\u001b[0;34m(self, grid, warmup, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m grid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grid):\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# Arguments are passed as a dict to `grid`, by contract.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# TODO(jlebar): In the new launch API, pass the compiler flags as a\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# second parameter to `grid`.\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m     grid \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m grid_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(grid)\n\u001b[1;32m    382\u001b[0m grid_0 \u001b[38;5;241m=\u001b[39m grid[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(meta)\u001b[0m\n\u001b[1;32m     28\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(N, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Launch the kernel with enough threads to exceed 'N'\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# This setup assumes launching one thread per data element\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m meta: (triton\u001b[38;5;241m.\u001b[39mcdiv(N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m256\u001b[39m, \u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBLOCK_SIZE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m),)\n\u001b[1;32m     33\u001b[0m scale_kernel[grid](X, SCALE, N, BLOCK_SIZE\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BLOCK_SIZE'"
     ]
    }
   ],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "# Define a simple kernel that attempts to scale an array\n",
    "@triton.jit\n",
    "def scale_kernel(X, SCALE, N, **meta):\n",
    "    # Compute the index of the thread (1D block and grid)\n",
    "    idx = tl.program_id(0)\n",
    "    \n",
    "    # Check bounds to avoid out-of-bounds access\n",
    "    if idx < N:\n",
    "        # Scale element at index 'idx' by a constant SCALE\n",
    "        X[idx] *= SCALE\n",
    "    # Deliberately introduce an out-of-bounds access error\n",
    "    else:\n",
    "        # This access is out of bounds when idx >= N\n",
    "        X[idx] = 0\n",
    "\n",
    "# Mock data and parameters\n",
    "import torch\n",
    "\n",
    "# Size of the array\n",
    "N = 1024\n",
    "# Scale factor\n",
    "SCALE = 2.0\n",
    "\n",
    "# Create a data array of size N on the GPU\n",
    "X = torch.ones(N, device='cuda', dtype=torch.float32)\n",
    "\n",
    "# Launch the kernel with enough threads to exceed 'N'\n",
    "# This setup assumes launching one thread per data element\n",
    "grid = lambda meta: (triton.cdiv(N + 256, meta['BLOCK_SIZE']),)\n",
    "scale_kernel[grid](X, SCALE, N, BLOCK_SIZE=1024)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

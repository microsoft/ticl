{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amueller-4gpu-eastus2-3\n"
     ]
    }
   ],
   "source": [
    "!echo $HOSTNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mothernet.evaluation.baselines import tabular_baselines\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)  # openml deprecation of array return type\n",
    "from mothernet.datasets import load_openml_list, open_cc_valid_dids, open_cc_dids\n",
    "from mothernet.evaluation.baselines.tabular_baselines import knn_metric, catboost_metric, logistic_metric, xgb_metric, random_forest_metric, mlp_metric, hyperfast_metric, hyperfast_metric_tuning, resnet_metric, mothernet_init_metric\n",
    "from mothernet.evaluation.tabular_evaluation import evaluate, eval_on_datasets, transformer_metric\n",
    "from mothernet.evaluation import tabular_metrics\n",
    "from mothernet.prediction.tabpfn import TabPFNClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 30\n"
     ]
    }
   ],
   "source": [
    "cc_test_datasets_multiclass, cc_test_datasets_multiclass_df = load_openml_list(open_cc_dids, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = 10000, num_feats=100, return_capped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "eval_positions = [1000]\n",
    "max_features = 100\n",
    "n_samples = 2000\n",
    "base_path = os.path.join('../')\n",
    "overwrite = False\n",
    "max_times = [1, 15, 30, 60, 60 * 5, 60 * 15, 60*60]\n",
    "metric_used = tabular_metrics.auc_metric\n",
    "task_type = 'multiclass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mothernet.evaluation.baselines.distill_mlp import DistilledTabPFNMLP\n",
    "from mothernet.prediction.mothernet import MotherNetClassifier\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline Evaluation\n",
    "This section runs baselines and saves results locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {base_path}/results\n",
    "!mkdir -p {base_path}/results/tabular/\n",
    "!mkdir -p {base_path}/results/tabular/multiclass/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc_test_datasets_multiclass_df['isNumeric'] = (cc_test_datasets_multiclass_df.NumberOfSymbolicFeatures == 1) & (cc_test_datasets_multiclass_df.NumberOfInstancesWithMissingValues == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rlrrr}\n",
      "\\toprule\n",
      "did & name & d & n & k \\\\\n",
      "\\midrule\n",
      "11 & balance-scale & 5 & 625 & 3 \\\\\n",
      "14 & mfeat-fourier & 77 & 2000 & 10 \\\\\n",
      "15 & breast-w & 10 & 699 & 2 \\\\\n",
      "16 & mfeat-karhunen & 65 & 2000 & 10 \\\\\n",
      "18 & mfeat-morphological & 7 & 2000 & 10 \\\\\n",
      "22 & mfeat-zernike & 48 & 2000 & 10 \\\\\n",
      "23 & cmc & 10 & 1473 & 3 \\\\\n",
      "29 & credit-approval & 16 & 690 & 2 \\\\\n",
      "31 & credit-g & 21 & 1000 & 2 \\\\\n",
      "37 & diabetes & 9 & 768 & 2 \\\\\n",
      "50 & tic-tac-toe & 10 & 958 & 2 \\\\\n",
      "54 & vehicle & 19 & 846 & 4 \\\\\n",
      "188 & eucalyptus & 20 & 736 & 5 \\\\\n",
      "458 & analcatdata_authorship & 71 & 841 & 4 \\\\\n",
      "469 & analcatdata_dmft & 5 & 797 & 6 \\\\\n",
      "1049 & pc4 & 38 & 1458 & 2 \\\\\n",
      "1050 & pc3 & 38 & 1563 & 2 \\\\\n",
      "1063 & kc2 & 22 & 522 & 2 \\\\\n",
      "1068 & pc1 & 22 & 1109 & 2 \\\\\n",
      "1462 & banknote-authentication & 5 & 1372 & 2 \\\\\n",
      "1464 & blood-transfusion-service-center & 5 & 748 & 2 \\\\\n",
      "1480 & ilpd & 11 & 583 & 2 \\\\\n",
      "1494 & qsar-biodeg & 42 & 1055 & 2 \\\\\n",
      "1510 & wdbc & 31 & 569 & 2 \\\\\n",
      "6332 & cylinder-bands & 40 & 540 & 2 \\\\\n",
      "23381 & dresses-sales & 13 & 500 & 2 \\\\\n",
      "40966 & MiceProtein & 82 & 1080 & 8 \\\\\n",
      "40975 & car & 7 & 1728 & 4 \\\\\n",
      "40982 & steel-plates-fault & 28 & 1941 & 7 \\\\\n",
      "40994 & climate-model-simulation-crashes & 21 & 540 & 2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc_test_datasets_multiclass_df['NumberOfInstances'] =  cc_test_datasets_multiclass_df['NumberOfInstances'].astype(int)\n",
    "cc_test_datasets_multiclass_df['NumberOfFeatures'] =  cc_test_datasets_multiclass_df['NumberOfFeatures'].astype(int)\n",
    "cc_test_datasets_multiclass_df['NumberOfClasses'] =  cc_test_datasets_multiclass_df['NumberOfClasses'].astype(int)\n",
    "\n",
    "print(cc_test_datasets_multiclass_df[['did', 'name', 'NumberOfFeatures', 'NumberOfInstances', 'NumberOfClasses']].rename(columns={'NumberOfFeatures': \"d\", \"NumberOfInstances\":\"n\", \"NumberOfClasses\": \"k\"}).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overlap:\n",
    "balance-scale\n",
    "mfeat-fourier\n",
    "mfeat-karhunen\n",
    "mfeat-morphological\n",
    "credit-g\n",
    "tic-tac-toe\n",
    "vehicle\n",
    "analcatdata_authorship\n",
    "analcatdata_dmft\n",
    "pc3\n",
    "pc1\n",
    "blood-transfusion-service-center\n",
    "ilpd\n",
    "qsar-biodeg\n",
    "MiceProtein\n",
    "car\n",
    "steel-plates-fault\n",
    "climate-simulation-model-crashes\n",
    "\n",
    "non-overlap:\n",
    "breast-w (valid)\n",
    "mfeat-zernike (valid)\n",
    "mcm (valid)\n",
    "eucalyptus (valid)\n",
    "wdbc (valid)\n",
    "cylinder-bands (valid)\n",
    "dresses-sales (valid)\n",
    "\n",
    "\n",
    "banknote-authentication (test)\n",
    "credit-approval (test)\n",
    "diabetes (test)\n",
    "pc4 (test)\n",
    "kc2 (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating resnet_gpu on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:01<00:00, 135.74it/s]\n"
     ]
    }
   ],
   "source": [
    "max_times = [60 * 60]\n",
    "# these will all be evaluated on CPU because they are given as callables, which is a weird way to do it.\n",
    "clf_dict= {\n",
    "    'resnet_gpu': resnet_metric}\n",
    "\n",
    "results_resnet = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_test_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, n_jobs=1, device=\"cuda:0\", verbose=0)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet_gd_gpu4 on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                                             | 8/20 [00:00<00:00, 69.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating balance-scale with 625 samples\n",
      "Evaluating balance-scale with 625 samples\n",
      "Evaluating balance-scale with 625 samples\n",
      "Evaluating balance-scale with 625 samples\n",
      "Evaluating balance-scale with 625 samples\n",
      "Evaluating mfeat-fourier with 2000 samples\n",
      "Evaluating mfeat-fourier with 2000 samples\n",
      "Evaluating mfeat-fourier with 2000 samples\n",
      "Evaluating mfeat-fourier with 2000 samples\n",
      "Evaluating mfeat-fourier with 2000 samples\n",
      "Evaluating breast-w with 699 samples\n",
      "Evaluating breast-w with 699 samples\n",
      "Evaluating breast-w with 699 samples\n",
      "Evaluating breast-w with 699 samples\n",
      "Evaluating breast-w with 699 samples\n",
      "Evaluating mfeat-karhunen with 2000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 58.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating mfeat-karhunen with 2000 samples\n",
      "Evaluating mfeat-karhunen with 2000 samples\n",
      "Evaluating mfeat-karhunen with 2000 samples\n",
      "Evaluating mfeat-karhunen with 2000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_times = [60 * 60]\n",
    "clf_dict= {\n",
    "    'mothernet_gd_gpu4': mothernet_init_metric}\n",
    "\n",
    "results_mothernet_gd = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_test_datasets_multiclass[:4], eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, n_jobs=1, device=\"cuda:0\", verbose=1)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating knn on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 524 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1050 out of 1050 | elapsed:   18.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating rf_new_params on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 1050 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1050 out of 1050 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating xgb on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1050 out of 1050 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating logistic on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1050 out of 1050 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mlp on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1050 out of 1050 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "from mothernet.evaluation.tabular_evaluation import eval_on_datasets\n",
    "max_times = [1, 5, 15, 60, 5 * 60, 15 * 60, 60* 60]\n",
    "\n",
    "clf_dict= {\n",
    "    'knn': knn_metric,\n",
    "    'rf_new_params': random_forest_metric,\n",
    "    'xgb': xgb_metric,\n",
    "    'logistic': logistic_metric,\n",
    "    'mlp': mlp_metric}\n",
    "\n",
    "results_baselines = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_test_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, fetch_only=True)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from mothernet.evaluation.tabular_evaluation import eval_on_datasets\n",
    "\n",
    "# max_times = [60 * 60]\n",
    "# clf_dict= {\n",
    "#     'hyperfast_tuning_gpu': hyperfast_metric_tuning}\n",
    "# results_hyperfast = [\n",
    "#     eval_on_datasets('multiclass', model, model_name, cc_test_datasets_multiclass[:8], eval_positions=eval_positions, max_times=max_times,\n",
    "#                      metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "#                      n_samples=n_samples, base_path=base_path, fetch_only=False, device='cuda:2')\n",
    "#     for model_name, model in clf_dict.items()\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mothernet on cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:01<00:00, 122.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mlp_distill on cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:01<00:00, 120.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating tabpfn on cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:01<00:00, 123.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ebm_bins_main_effects on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   39.1s\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/anaconda/envs/tabpfn_testing_environment/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:723: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating baam_nfeatures_20_no_ensemble_e1520 on cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:16<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8 on cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:01<00:00, 122.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from mothernet.evaluation.tabular_evaluation import eval_on_datasets\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from mothernet.prediction.mothernet import ShiftClassifier, EnsembleMeta, MotherNetClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from mothernet.prediction.mothernet_additive import MotherNetAdditiveClassifier\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "\n",
    "from hyperfast import HyperFastClassifier\n",
    "\n",
    "# transformers don't have max times\n",
    "import warnings\n",
    "max_times = [1]\n",
    "device = \"cuda:2\"\n",
    "\n",
    "model_string = \"tabpfn_nooptimizer_emsize_512_nlayers_12_steps_2048_bs_32ada_lr_0.0001_1_gpu_07_24_2023_01_43_33\"\n",
    "tabpfn_ours = TabPFNClassifier(device=device, model_string=model_string, epoch=\"1650\", N_ensemble_configurations=3)\n",
    "mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_Dclass_average_03_25_2024_17_14_32_epoch_2910.cpkt\", device=device), n_estimators=8, onehot=True)\n",
    "\n",
    "mlp_distill = make_pipeline(StandardScaler(), DistilledTabPFNMLP(n_epochs=1000, device=device, hidden_size=128, n_layers=2, dropout_rate=.1, learning_rate=0.01, model_string=model_string, epoch=1650, N_ensemble_configurations=3))\n",
    "mothernet_21_46_25_3940_ensemble3 = EnsembleMeta(MotherNetClassifier(path=\"../models_diff/mn_d2048_H4096_L2_W32_P512_1_gpu_warm_08_25_2023_21_46_25_epoch_3940_no_optimizer.pickle\", device=device), n_estimators=3)\n",
    "ebm_bins_main_effects = ExplainableBoostingClassifier(max_bins=64, interactions=0)\n",
    "baam_nfeatures_20_no_ensemble_e1520 = MotherNetAdditiveClassifier(path=\"../models_diff/baam_H512_Dclass_average_e128_nsamples500_numfeatures20_padzerosFalse_03_14_2024_15_03_22_epoch_1520.cpkt\", device=device)\n",
    "\n",
    "clf_dict= {\n",
    "    'mothernet': partial(transformer_metric, classifier=mothernet_21_46_25_3940_ensemble3, onehot=True),\n",
    "    'mlp_distill': mlp_distill,\n",
    "    'tabpfn': transformer_metric,\n",
    "    #'tabpfn_ours': tabpfn_ours,\n",
    "    #\"hyperfast_no_optimize_gpu\": partial(hyperfast_metric, optimization=None),\n",
    "    #\"hyperfast_defaults_gpu\": hyperfast_metric,\n",
    "    'ebm_bins_main_effects': ebm_bins_main_effects,\n",
    "    'baam_nfeatures_20_no_ensemble_e1520': baam_nfeatures_20_no_ensemble_e1520,\n",
    "    'mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8': mn_Dclass_average_03_25_2024_17_14_32_epoch_2910_ohe_ensemble_8,\n",
    "\n",
    "    }\n",
    "results_transformers = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_test_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, overwrite=False, n_jobs=1, device=device)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "flat_results = []\n",
    "for per_dataset in results_baselines + results_transformers:\n",
    "    for result in per_dataset:\n",
    "        row = {}\n",
    "        for key in ['dataset', 'model', 'mean_metric', 'split', 'max_time']:\n",
    "            row[key] = result[key]\n",
    "        best_configs_key, = [k for k in result.keys() if \"best_configs\" in k]\n",
    "        if result[best_configs_key][0] is not None:\n",
    "            row.update(result[best_configs_key][0])\n",
    "        row['mean_metric'] = float(row[\"mean_metric\"].numpy())\n",
    "        flat_results.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(flat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>mean_metric</th>\n",
       "      <th>split</th>\n",
       "      <th>max_time</th>\n",
       "      <th>best</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>inference_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.898451</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 14}</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.031152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.848925</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.026842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.852651</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.027301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.885874</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.028868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balance-scale</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.895205</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.027410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>mn_Dclass_average_03_25_2024_17_14_32_epoch_29...</td>\n",
       "      <td>0.937723</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317008</td>\n",
       "      <td>0.049277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>mn_Dclass_average_03_25_2024_17_14_32_epoch_29...</td>\n",
       "      <td>0.943915</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.313077</td>\n",
       "      <td>0.034901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>mn_Dclass_average_03_25_2024_17_14_32_epoch_29...</td>\n",
       "      <td>0.939702</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.398591</td>\n",
       "      <td>0.036673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>mn_Dclass_average_03_25_2024_17_14_32_epoch_29...</td>\n",
       "      <td>0.944275</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.313154</td>\n",
       "      <td>0.035129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>mn_Dclass_average_03_25_2024_17_14_32_epoch_29...</td>\n",
       "      <td>0.966092</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374892</td>\n",
       "      <td>0.035624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dataset  \\\n",
       "0                        balance-scale   \n",
       "1                        balance-scale   \n",
       "2                        balance-scale   \n",
       "3                        balance-scale   \n",
       "4                        balance-scale   \n",
       "...                                ...   \n",
       "6145  climate-model-simulation-crashes   \n",
       "6146  climate-model-simulation-crashes   \n",
       "6147  climate-model-simulation-crashes   \n",
       "6148  climate-model-simulation-crashes   \n",
       "6149  climate-model-simulation-crashes   \n",
       "\n",
       "                                                  model  mean_metric  split  \\\n",
       "0                                                   knn     0.898451      1   \n",
       "1                                                   knn     0.848925      2   \n",
       "2                                                   knn     0.852651      3   \n",
       "3                                                   knn     0.885874      4   \n",
       "4                                                   knn     0.895205      5   \n",
       "...                                                 ...          ...    ...   \n",
       "6145  mn_Dclass_average_03_25_2024_17_14_32_epoch_29...     0.937723      1   \n",
       "6146  mn_Dclass_average_03_25_2024_17_14_32_epoch_29...     0.943915      2   \n",
       "6147  mn_Dclass_average_03_25_2024_17_14_32_epoch_29...     0.939702      3   \n",
       "6148  mn_Dclass_average_03_25_2024_17_14_32_epoch_29...     0.944275      4   \n",
       "6149  mn_Dclass_average_03_25_2024_17_14_32_epoch_29...     0.966092      5   \n",
       "\n",
       "      max_time                 best  fit_time  inference_time  \n",
       "0            1  {'n_neighbors': 14}  0.000790        0.031152  \n",
       "1            1   {'n_neighbors': 8}  0.000795        0.026842  \n",
       "2            1  {'n_neighbors': 10}  0.000851        0.027301  \n",
       "3            1  {'n_neighbors': 10}  0.000786        0.028868  \n",
       "4            1  {'n_neighbors': 15}  0.000829        0.027410  \n",
       "...        ...                  ...       ...             ...  \n",
       "6145         1                  NaN  0.317008        0.049277  \n",
       "6146         1                  NaN  0.313077        0.034901  \n",
       "6147         1                  NaN  0.398591        0.036673  \n",
       "6148         1                  NaN  0.313154        0.035129  \n",
       "6149         1                  NaN  0.374892        0.035624  \n",
       "\n",
       "[6150 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open(\"results_test.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(results_baselines + results_transformers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df['model'] = results_df.model.replace({'knn': \"KNN\", 'rf_new_params': 'RF', 'mlp': \"MLP\",'mlp_distill': 'MLP-Distill', 'xgb':'XGBoost', 'logistic': 'LogReg',  'mothernet': 'MotherNet', 'tabpfn': 'TabPFN (Hollmann)', 'tabpfn_ours': 'TabPFN (ours)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results_test_2024-04-18.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "filename = f\"results_test_{datetime.date.today()}.csv\"\n",
    "results_df.to_csv(filename)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mothernet]",
   "language": "python",
   "name": "conda-env-mothernet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
